{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc533668",
   "metadata": {},
   "source": [
    "converting the acouslic ai .mha files (combining the images, masks and circumference) into .npz files for faster processing during training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7af003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "\n",
    "def load_ac_csv(csv_path):\n",
    "    \"\"\"Load abdominal circumference CSV as DataFrame with UUID as index.\"\"\"\n",
    "    df = pd.read_csv(csv_path).set_index(\"uuid\")\n",
    "    return df\n",
    "\n",
    "def get_reference_ac(ac_df, uuid):\n",
    "    \"\"\"Get the first available sweep AC measurement for a given UUID.\"\"\"\n",
    "    try:\n",
    "        ac_row = ac_df.loc[uuid]\n",
    "        ac_values = ac_row.filter(like='sweep_').dropna().values\n",
    "        return float(ac_values[0]) if len(ac_values) > 0 else None\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error fetching AC for {uuid}: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_acouslic_dataset(\n",
    "    image_dir,\n",
    "    mask_dir,\n",
    "    csv_path,\n",
    "    output_dir,\n",
    "    limit=None,  # convert all if None\n",
    "    pixel_spacing=0.28,\n",
    "    add_channel_dim=False\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ac_df = load_ac_csv(csv_path)\n",
    "\n",
    "    mha_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".mha\")])\n",
    "    converted = 0\n",
    "\n",
    "    for f in tqdm(mha_files, desc=\"Converting ACOUSLIC cases\"):\n",
    "        if limit is not None and converted >= limit:\n",
    "            break\n",
    "\n",
    "        case_id = f.replace(\".mha\", \"\")\n",
    "        uuid = case_id  # assumes filenames are UUIDs\n",
    "\n",
    "        image_path = os.path.join(image_dir, f)\n",
    "        mask_path = os.path.join(mask_dir, f)\n",
    "        output_path = os.path.join(output_dir, f\"{case_id}.npz\")\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"ℹ️ Skipping {case_id}: already exists.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Load MHA image and mask\n",
    "            img = sitk.ReadImage(image_path)\n",
    "            mask = sitk.ReadImage(mask_path)\n",
    "\n",
    "            img_np = sitk.GetArrayFromImage(img).astype(np.float32)   # [T, H, W]\n",
    "            mask_np = sitk.GetArrayFromImage(mask).astype(np.uint8)   # [T, H, W]\n",
    "\n",
    "            if img_np.shape != mask_np.shape:\n",
    "                print(f\"⚠️ Shape mismatch for {case_id}: image={img_np.shape}, mask={mask_np.shape}\")\n",
    "                continue\n",
    "\n",
    "            # Normalize image to [0, 1]\n",
    "            img_np -= img_np.min()\n",
    "            img_np /= (img_np.max() + 1e-8)\n",
    "\n",
    "            # Optional: Add channel dimension -> [T, 1, H, W]\n",
    "            if add_channel_dim:\n",
    "                img_np = img_np[:, np.newaxis, :, :]\n",
    "                mask_np = mask_np[:, np.newaxis, :, :]\n",
    "\n",
    "            # Binary classification label (per frame)\n",
    "            label = ((mask_np > 0).any(axis=(1, 2))).astype(np.uint8)  # [T]\n",
    "            if add_channel_dim:\n",
    "                label = ((mask_np > 0).any(axis=(1, 2, 3))).astype(np.uint8)\n",
    "\n",
    "            # Get ground-truth abdominal circumference\n",
    "            ac_mm = get_reference_ac(ac_df, uuid)\n",
    "            if ac_mm is None:\n",
    "                print(f\"⚠️ Missing AC value for {uuid}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Save to .npz\n",
    "            np.savez_compressed(\n",
    "                output_path,\n",
    "                image=img_np.astype(np.float32),\n",
    "                mask=mask_np.astype(np.uint8),\n",
    "                label=label.astype(np.uint8),\n",
    "                pixel_spacing=np.float32(pixel_spacing),\n",
    "                ac_reference=np.float32(ac_mm),\n",
    "                uuid=uuid\n",
    "            )\n",
    "\n",
    "            print(f\"✅ Saved {case_id} | AC: {ac_mm:.2f} mm | Frames: {img_np.shape[0]}\")\n",
    "            converted += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {case_id}: {e}\")\n",
    "            traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13646c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_acouslic_dataset(\n",
    "    image_dir=\"/kaggle/input/acouslic-ai-dataset/acouslic-ai-train-set/images/stacked_fetal_ultrasound\",\n",
    "    mask_dir=\"/kaggle/input/acouslic-ai-dataset/acouslic-ai-train-set/masks/stacked_fetal_abdomen\",\n",
    "    csv_path=\"/kaggle/input/acouslic-ai-dataset/acouslic-ai-train-set/circumferences/fetal_abdominal_circumferences_per_sweep.csv\",\n",
    "    output_dir=\"/kaggle/working/converted_npz\",\n",
    "    limit=5 #Testing with 5 conversions\n",
    "    pixel_spacing=0.28,\n",
    "    add_channel_dim=False  # set to True if your model needs [C,H,W]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac32184",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = np.load(\"/kaggle/working/converted_npz/0199616b-bdeb-4119-97a3-a5a3571bd641.npz\")\n",
    "print(case.files)\n",
    "print(case[\"image\"].shape, case[\"mask\"].shape, case[\"label\"].shape)\n",
    "print(\"Pixel spacing:\", case[\"pixel_spacing\"])\n",
    "print(\"Ground-truth AC (mm):\", case[\"ac_reference\"])\n",
    "\n",
    "case = np.load(\"/kaggle/working/converted_npz/02d3a9bc-63e2-4deb-9dc1-dba17e7d54c1.npz\")\n",
    "print(case.files)\n",
    "print(case[\"image\"].shape, case[\"mask\"].shape, case[\"label\"].shape)\n",
    "print(\"Pixel spacing:\", case[\"pixel_spacing\"])\n",
    "print(\"Ground-truth AC (mm):\", case[\"ac_reference\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your .npz file\n",
    "case = np.load(\"/kaggle/working/converted_npz/046ed03e-4b35-4519-bb5f-cd4b0474a060.npz\")\n",
    "\n",
    "images = case[\"image\"]       # shape: (840, H, W)\n",
    "masks = case[\"mask\"]         # shape: (840, H, W)\n",
    "labels = case[\"label\"]       # shape: (840,)\n",
    "\n",
    "print(f\"Frames with positive label: {np.sum(labels)} / {len(labels)}\")\n",
    "\n",
    "# Plot classification labels as a timeline\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.title(\"Frame classification labels (1=has annotation, 0=no annotation)\")\n",
    "plt.plot(labels, drawstyle='steps-mid')\n",
    "plt.xlabel(\"Frame number\")\n",
    "plt.ylabel(\"Label\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize a few example frames with segmentation masks overlayed\n",
    "def show_frame_with_mask(frame_idx):\n",
    "    img = images[frame_idx]\n",
    "    mask = masks[frame_idx]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(f\"Frame {frame_idx} — Label: {labels[frame_idx]}\")\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    # Overlay mask with transparency; use colors for mask values 1 and 2\n",
    "    # Create colored mask overlay\n",
    "    mask_overlay = np.zeros((*mask.shape, 4))  # RGBA\n",
    "\n",
    "    # Optimal mask (1) - Red with alpha\n",
    "    mask_overlay[mask == 1] = [1, 0, 0, 0.4]\n",
    "    # Suboptimal mask (2) - Blue with alpha\n",
    "    mask_overlay[mask == 2] = [0, 0, 1, 0.4]\n",
    "\n",
    "    plt.imshow(mask_overlay)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Show first 3 frames that have annotations\n",
    "annotated_frames = np.where(labels == 1)[0]\n",
    "for idx in annotated_frames[:50]:\n",
    "    show_frame_with_mask(idx)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
