{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997d0a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21761a987b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random, math, numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "try:\n",
    "    # torchvision v2 transforms (tensor-native)\n",
    "    from torchvision.transforms import v2 as T\n",
    "except:\n",
    "    # fallback to classic, but v2 is recommended\n",
    "    import torchvision.transforms as T\n",
    "    \n",
    "# --- put these at top-level (not inside a function/cell) ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AddGaussianNoise(nn.Module):\n",
    "    def __init__(self, std=0.03):\n",
    "        super().__init__()\n",
    "        self.std = float(std)\n",
    "    def forward(self, x):\n",
    "        return x + torch.randn_like(x) * self.std if self.std > 0 else x\n",
    "\n",
    "class NoOp(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----- Paths (edit these) -----\n",
    "TRAIN_DIR = \"D:/dataset/npz_80_tiny\"                   # reduced, balanced-ish for training\n",
    "VAL_DIR   = \"D:/dataset/converted_classifier_npz_compact\"  # full-length compacts for validation/inference\n",
    "SAVE_PATH = \"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_BYOL.pth\"\n",
    "\n",
    "# ----- Splits (edit indices as you like) -----\n",
    "train_files = sorted([f for f in os.listdir(TRAIN_DIR) if f.endswith(\".npz\")])[:210]\n",
    "val_files   = sorted([f for f in os.listdir(VAL_DIR)   if f.endswith(\".npz\")])[210:255]\n",
    "\n",
    "# ----- Training hyperparams -----\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH  = 64\n",
    "EPOCHS     = 20\n",
    "PATIENCE   = 5\n",
    "LR_HEAD    = 1e-3     # warmup (head-only)\n",
    "LR_ALL     = 1e-4     # full fine-tune\n",
    "WEIGHT_DEC = 1e-4\n",
    "SEED       = 42\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45e1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _letterbox_to_square(x: torch.Tensor, size: int = 224) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: (B,1,H,W) or (1,H,W) in [0,1] -> pad to square (keep aspect) -> resize to (..,1,size,size)\n",
    "    \"\"\"\n",
    "    is_batched = (x.dim() == 4)\n",
    "    if not is_batched:\n",
    "        x = x.unsqueeze(0)  # (1,1,H,W)\n",
    "    _, _, H, W = x.shape\n",
    "    s = max(H, W)\n",
    "    pad_h = (s - H) // 2\n",
    "    pad_w = (s - W) // 2\n",
    "    x = F.pad(x, (pad_w, s - W - pad_w, pad_h, s - H - pad_h))  # L,R,T,B\n",
    "    x = F.interpolate(x, size=(size, size), mode=\"bilinear\", align_corners=False)\n",
    "    return x if is_batched else x.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6460bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreloadedNPZFrameDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 npz_dir: str,\n",
    "                 files: list[str],\n",
    "                 binary: bool = True,\n",
    "                 out_size: int = 224,\n",
    "                 resize_mode: str = \"letterbox\",\n",
    "                 dtype: torch.dtype = torch.float16):\n",
    "        self.binary = binary\n",
    "        self.out_size = out_size\n",
    "        self.resize_mode = resize_mode\n",
    "        self.dtype = dtype\n",
    "\n",
    "        imgs_all, labels_all, pids_all = [], [], []   # <-- NEW\n",
    "\n",
    "        for f in files:\n",
    "            path = os.path.join(npz_dir, f)\n",
    "            case = np.load(path, allow_pickle=True)\n",
    "            imgs = case[\"image\"]                    # (T,H,W) uint8\n",
    "            y    = case[\"label\"].astype(np.int64)   # (T,)\n",
    "            if binary:\n",
    "                y[y == 2] = 1\n",
    "\n",
    "            # patient ID per frame: prefer uuid inside the npz; fallback to filename stem\n",
    "            pid = str(case[\"uuid\"]) if \"uuid\" in case else os.path.splitext(f)[0]\n",
    "            tframes = imgs.shape[0]\n",
    "            pids_all.append(torch.full((tframes,), hash(pid) & 0x7fffffff, dtype=torch.int64))  # stable int pid\n",
    "\n",
    "            t = torch.from_numpy(imgs).unsqueeze(1).float() / 255.0  # (T,1,H,W) [0,1]\n",
    "            if resize_mode == \"letterbox\":\n",
    "                out_frames = [ _letterbox_to_square(fr, size=out_size) for fr in t ]\n",
    "                t = torch.stack(out_frames, dim=0)  # (T,1,S,S)\n",
    "            else:\n",
    "                t = F.interpolate(t, size=(out_size, out_size), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            t = (t - 0.5) / 0.5  # [-1,1]\n",
    "            imgs_all.append(t.to(dtype=dtype).cpu())\n",
    "            labels_all.append(torch.from_numpy(y).long())\n",
    "\n",
    "        self.images = torch.cat(imgs_all, dim=0)            # (N,1,S,S)\n",
    "        self.labels = torch.cat(labels_all, dim=0)          # (N,)\n",
    "        self.patient_ids = torch.cat(pids_all, dim=0)       # (N,)  <-- NEW\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.numel()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23acc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class PatientAwareBalancedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    50/50 pos/neg batches that also mix patients.\n",
    "    - Uses every positive once per epoch (finite).\n",
    "    - Negatives are sampled to match.\n",
    "    - frames_per_patient_side controls per-patient contribution per side.\n",
    "\n",
    "    labels:       list/1D tensor of {0,1}\n",
    "    patient_ids:  list/1D tensor of ints (aligned with labels)\n",
    "    batch_size:   even\n",
    "    frames_per_patient_side: e.g., 2 -> up to 2 pos from a patient and up to 2 neg from a patient per batch\n",
    "    \"\"\"\n",
    "    def __init__(self, labels, patient_ids, batch_size=32, frames_per_patient_side=2, pos_label=1, seed=42):\n",
    "        assert batch_size % 2 == 0 and batch_size >= 2\n",
    "        self.labels = list(map(int, labels))\n",
    "        self.pids   = list(map(int, patient_ids))\n",
    "        self.half   = batch_size // 2\n",
    "        self.k      = max(1, int(frames_per_patient_side))\n",
    "        self.pos_label = pos_label\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "        # Build per-patient pools\n",
    "        pos_by_pid = defaultdict(list)\n",
    "        neg_by_pid = defaultdict(list)\n",
    "        for i, (y, pid) in enumerate(zip(self.labels, self.pids)):\n",
    "            if y == pos_label: pos_by_pid[pid].append(i)\n",
    "            elif y == 0:       neg_by_pid[pid].append(i)\n",
    "\n",
    "        if not pos_by_pid or not neg_by_pid:\n",
    "            raise ValueError(\"Need patients with both pos and neg frames.\")\n",
    "\n",
    "        self.pos_by_pid = {pid: idxs for pid, idxs in pos_by_pid.items() if idxs}\n",
    "        self.neg_by_pid = {pid: idxs for pid, idxs in neg_by_pid.items() if idxs}\n",
    "        self.pos_patients = list(self.pos_by_pid.keys())\n",
    "        self.neg_patients = list(self.neg_by_pid.keys())\n",
    "\n",
    "        # Steps per epoch: exhaust positives once\n",
    "        self.num_pos = sum(len(v) for v in self.pos_by_pid.values())\n",
    "        self.steps   = math.ceil(self.num_pos / self.half)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def _multi_patient_take(self, pools_by_pid, patient_ids, need):\n",
    "        \"\"\"\n",
    "        Take 'need' indices by visiting many patients, up to self.k per patient.\n",
    "        Refill per-patient shuffled pools when everyone is exhausted.\n",
    "        \"\"\"\n",
    "        rng = self.rng\n",
    "        out = []\n",
    "        # Build shuffled per-patient pools\n",
    "        active = {pid: rng.sample(idxs, k=len(idxs)) for pid, idxs in pools_by_pid.items()}\n",
    "        ring = patient_ids[:]\n",
    "        rng.shuffle(ring)\n",
    "        head = 0\n",
    "\n",
    "        while len(out) < need:\n",
    "            if head >= len(ring):\n",
    "                head = 0\n",
    "                rng.shuffle(ring)\n",
    "            pid = ring[head]; head += 1\n",
    "            pool = active.get(pid, [])\n",
    "            if not pool:\n",
    "                continue\n",
    "            take = min(self.k, len(pool), need - len(out))\n",
    "            out.extend(pool[:take])\n",
    "            active[pid] = pool[take:]\n",
    "\n",
    "            # if everyone empty, refill\n",
    "            if all(len(v) == 0 for v in active.values()):\n",
    "                active = {pid: rng.sample(pools_by_pid[pid], k=len(pools_by_pid[pid])) for pid in pools_by_pid}\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = self.rng\n",
    "\n",
    "        # Flat list of all positives, shuffled; ensure enough for steps*half\n",
    "        all_pos = []\n",
    "        for pid, idxs in self.pos_by_pid.items():\n",
    "            all_pos.extend(idxs)\n",
    "        rng.shuffle(all_pos)\n",
    "\n",
    "        total_pos_needed = self.steps * self.half\n",
    "        if len(all_pos) < total_pos_needed:\n",
    "            reps = math.ceil(total_pos_needed / len(all_pos))\n",
    "            all_pos = (all_pos * reps)[:total_pos_needed]\n",
    "        else:\n",
    "            all_pos = all_pos[:total_pos_needed]\n",
    "\n",
    "        pos_cursor = 0\n",
    "\n",
    "        for _ in range(self.steps):\n",
    "            # Positives: take next chunk then redistribute to mix patients (cap k/patient)\n",
    "            pos_slice = all_pos[pos_cursor: pos_cursor + self.half]\n",
    "            pos_cursor += self.half\n",
    "\n",
    "            # Bucket that slice by patient\n",
    "            by_pid = defaultdict(list)\n",
    "            for i in pos_slice:\n",
    "                by_pid[self.pids[i]].append(i)\n",
    "\n",
    "            # Take up to k per patient, top-up if needed\n",
    "            p_batch = []\n",
    "            pids_shuf = list(by_pid.keys())\n",
    "            rng.shuffle(pids_shuf)\n",
    "            for pid in pids_shuf:\n",
    "                take = min(self.k, len(by_pid[pid]), self.half - len(p_batch))\n",
    "                if take > 0:\n",
    "                    p_batch.extend(by_pid[pid][:take])\n",
    "                if len(p_batch) == self.half: break\n",
    "            if len(p_batch) < self.half:\n",
    "                # top up from leftovers in this slice\n",
    "                extras = []\n",
    "                for pid in pids_shuf:\n",
    "                    extras.extend(by_pid[pid][self.k:])\n",
    "                p_batch = (p_batch + extras)[:self.half]\n",
    "\n",
    "            # Negatives: sample across many patients (cap k/patient)\n",
    "            n_batch = self._multi_patient_take(self.neg_by_pid, self.neg_patients, self.half)\n",
    "\n",
    "            batch = p_batch + n_batch\n",
    "            rng.shuffle(batch)\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a6d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class FrameClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        except:\n",
    "            backbone = models.resnet50(pretrained=True)\n",
    "\n",
    "        # replace first conv (3→1 channels)\n",
    "        old = backbone.conv1  # (64,3,7,7)\n",
    "        new = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            new.weight.copy_(old.weight.mean(dim=1, keepdim=True))  # average RGB to gray\n",
    "        backbone.conv1 = new\n",
    "\n",
    "        # replace classifier head\n",
    "        backbone.fc = nn.Linear(backbone.fc.in_features, num_classes)\n",
    "\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4027b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05).to(device)\n",
    "# criterion = FocalLoss(alpha=(1.0, 1.3), gamma=2.0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463adf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAFE, ULTRASOUND-FRIENDLY AUGS\n",
    "try:\n",
    "    from torchvision.transforms import v2 as T\n",
    "    _HAS_V2 = True\n",
    "except:\n",
    "    import torchvision.transforms as T\n",
    "    _HAS_V2 = False\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.3),                 # common probe orientation change\n",
    "    T.RandomVerticalFlip(p=0.1),                   # rarer; OK but small prob\n",
    "    T.RandomRotation(degrees=15),                  # small tilt\n",
    "    T.RandomAffine(degrees=0, translate=(0.08, 0.08), scale=(0.9, 1.1)),  # ±8% shift, ±10% zoom\n",
    "\n",
    "    # intensity realism (no hue/sat for grayscale)\n",
    "    T.RandomApply([T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))], p=0.2),\n",
    "    T.RandomApply([T.Lambda(lambda x: x + 0.03 * torch.randn_like(x))], p=0.2),\n",
    "    # NOTE: no Normalize here (your dataset already did (t-0.5)/0.5 → [-1,1])\n",
    "])\n",
    "\n",
    "# validation: true no-op\n",
    "val_tf = T.Compose([T.Identity()]) if _HAS_V2 else T.Compose([T.Lambda(lambda x: x)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8fc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WithTransform(Dataset):\n",
    "    def __init__(self, base: Dataset, transform=None):\n",
    "        self.base = base\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base[idx]        # x: (1,S,S), currently FP16 and already in [-1,1]\n",
    "        x = x.to(dtype=torch.float32)\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fa6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base datasets (already normalize to [-1,1] inside PreloadedNPZFrameDataset)\n",
    "train_ds_base = PreloadedNPZFrameDataset(TRAIN_DIR, train_files, binary=True, out_size=IMAGE_SIZE)\n",
    "val_ds_base   = PreloadedNPZFrameDataset(VAL_DIR,   val_files,   binary=True, out_size=IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40717c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = PatientAwareBalancedBatchSampler(\n",
    "    labels=train_ds_base.labels.tolist(),\n",
    "    patient_ids=train_ds_base.patient_ids.tolist(),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    frames_per_patient_side=2,   # try 1–2; increase if you want more patients per batch\n",
    "    pos_label=1,\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6d400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WithTransform(train_ds_base, transform=train_tf)   # your safe train_tf\n",
    "val_ds   = WithTransform(val_ds_base,   transform=val_tf)     # no-op for val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a10f4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_sampler=train_sampler,    # NOTE: batch_sampler (do NOT also pass batch_size)\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=VAL_BATCH,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d2cde",
   "metadata": {},
   "source": [
    "#### byol pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e890cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 1/30: 100%|██████████| 131/131 [02:14<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: BYOL loss 0.7304 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 1) | loss 0.7304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 2/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: BYOL loss 0.3747 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 2) | loss 0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 3/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: BYOL loss 0.2114 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 3) | loss 0.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 4/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: BYOL loss 0.1342 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 4) | loss 0.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 5/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: BYOL loss 0.0943 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 5) | loss 0.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 6/30: 100%|██████████| 131/131 [02:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: BYOL loss 0.0717 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 6) | loss 0.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 7/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: BYOL loss 0.0574 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 7) | loss 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 8/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: BYOL loss 0.0485 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 8) | loss 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 9/30: 100%|██████████| 131/131 [02:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: BYOL loss 0.0417 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 9) | loss 0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 10/30: 100%|██████████| 131/131 [02:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: BYOL loss 0.0369 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 10) | loss 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 11/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: BYOL loss 0.0338 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 11) | loss 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 12/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: BYOL loss 0.0314 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 12) | loss 0.0314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 13/30: 100%|██████████| 131/131 [02:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: BYOL loss 0.0291 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 13) | loss 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 14/30: 100%|██████████| 131/131 [02:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: BYOL loss 0.0276 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 14) | loss 0.0276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 15/30: 100%|██████████| 131/131 [02:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: BYOL loss 0.0266 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 15) | loss 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 16/30: 100%|██████████| 131/131 [02:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: BYOL loss 0.0255 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 16) | loss 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 17/30: 100%|██████████| 131/131 [02:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: BYOL loss 0.0241 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 17) | loss 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 18/30: 100%|██████████| 131/131 [02:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: BYOL loss 0.0234 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 18) | loss 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 19/30: 100%|██████████| 131/131 [02:06<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: BYOL loss 0.0228 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 19) | loss 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 20/30: 100%|██████████| 131/131 [02:03<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: BYOL loss 0.0224 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 20) | loss 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 21/30: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: BYOL loss 0.0217 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 21) | loss 0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 22/30: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: BYOL loss 0.0212 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 22) | loss 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 23/30: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: BYOL loss 0.0209 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 23) | loss 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 24/30: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: BYOL loss 0.0207 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 24) | loss 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 25/30: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: BYOL loss 0.0205 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 25) | loss 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 26/30: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: BYOL loss 0.0203 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 26) | loss 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 27/30: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: BYOL loss 0.0203 (lower is better; 0 is ideal)\n",
      "No improvement (1/7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 28/30: 100%|██████████| 131/131 [02:06<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: BYOL loss 0.0200 (lower is better; 0 is ideal)\n",
      "✅ Saved BEST (epoch 28) | loss 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 29/30: 100%|██████████| 131/131 [02:04<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: BYOL loss 0.0200 (lower is better; 0 is ideal)\n",
      "No improvement (1/7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BYOL pretrain 30/30: 100%|██████████| 131/131 [02:02<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: BYOL loss 0.0201 (lower is better; 0 is ideal)\n",
      "No improvement (2/7)\n",
      "Best epoch: 28 | Best BYOL loss: 0.0200\n",
      "Best encoder saved at: D:/acouslic-ai-cse4622/saved_weights\\byol_encoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== BYOL pretrain for grayscale ResNet50 (Windows-safe, AMP, early stopping) =====\n",
    "import os, math, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import amp\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ---------------- small, picklable helper transforms ----------------\n",
    "class AddGaussianNoise(nn.Module):\n",
    "    def __init__(self, std=0.03):\n",
    "        super().__init__()\n",
    "        self.std = float(std)\n",
    "    def forward(self, x):\n",
    "        if self.std <= 0: return x\n",
    "        return x + torch.randn_like(x) * self.std\n",
    "\n",
    "class TwoCropsTransform(nn.Module):\n",
    "    \"\"\"Return two independently augmented views.\"\"\"\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "    def forward(self, x):\n",
    "        v1 = self.base(x)\n",
    "        v2 = self.base(x)\n",
    "        return v1, v2\n",
    "\n",
    "# ---------------- SSL-friendly augs (operate on [-1,1] tensors) ----------------\n",
    "try:\n",
    "    from torchvision.transforms import v2 as T\n",
    "    _V2 = True\n",
    "except:\n",
    "    import torchvision.transforms as T\n",
    "    _V2 = False\n",
    "\n",
    "ssl_base_aug = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.3),\n",
    "    T.RandomVerticalFlip(p=0.1),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.RandomAffine(degrees=0, translate=(0.08,0.08), scale=(0.9,1.1)),\n",
    "    T.RandomApply([T.GaussianBlur(kernel_size=3, sigma=(0.1,1.0))], p=0.2),\n",
    "    T.RandomApply([AddGaussianNoise(0.03)], p=0.2),\n",
    "])\n",
    "ssl_transform = TwoCropsTransform(ssl_base_aug)\n",
    "\n",
    "# ---------------- Dataset wrapper: returns (view1, view2) ----------------\n",
    "class SSLPairDataset(Dataset):\n",
    "    def __init__(self, base_ds: Dataset, transform):\n",
    "        self.base = base_ds\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x, _ = self.base[idx]          # x: (1,S,S) fp16 in [-1,1]\n",
    "        x = x.to(torch.float32)        # augs in fp32\n",
    "        v1, v2 = self.transform(x)\n",
    "        return v1, v2\n",
    "\n",
    "# ---------------- BYOL components ----------------\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    # 2-layer MLP with BN (as common for BYOL/SimSiam)\n",
    "    def __init__(self, in_dim, hidden=2048, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden, bias=False),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim, bias=True)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, in_dim=256, hidden=256, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden, bias=False),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "def build_resnet50_gray(imagenet_init=True):\n",
    "    # ResNet50 with 1-channel conv1 and fc=Identity (encoder only)\n",
    "    try:\n",
    "        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if imagenet_init else None)\n",
    "    except:\n",
    "        backbone = models.resnet50(pretrained=imagenet_init)\n",
    "    old = backbone.conv1\n",
    "    new = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    with torch.no_grad():\n",
    "        if old.weight.shape[1] == 3:\n",
    "            new.weight.copy_(old.weight.mean(dim=1, keepdim=True))\n",
    "        else:\n",
    "            nn.init.kaiming_normal_(new.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "    backbone.conv1 = new\n",
    "    feat_dim = backbone.fc.in_features\n",
    "    backbone.fc = nn.Identity()\n",
    "    return backbone, feat_dim\n",
    "\n",
    "class BYOL(nn.Module):\n",
    "    \"\"\"\n",
    "    Online: encoder + projector + predictor\n",
    "    Target: EMA(encoder + projector)  (no predictor)\n",
    "    Loss: 0.5 * [ 2 - 2*cos(p1, t2) ] + 0.5 * [ 2 - 2*cos(p2, t1) ]\n",
    "    \"\"\"\n",
    "    def __init__(self, imagenet_init=True, tau_base=0.996):\n",
    "        super().__init__()\n",
    "        enc_online, feat_dim = build_resnet50_gray(imagenet_init=imagenet_init)\n",
    "        self.online_encoder = enc_online\n",
    "        self.online_proj    = Projector(feat_dim, hidden=2048, out_dim=256)\n",
    "        self.predictor      = Predictor(256, hidden=256, out_dim=256)\n",
    "\n",
    "        # target = EMA copies\n",
    "        self.target_encoder = copy.deepcopy(self.online_encoder)\n",
    "        self.target_proj    = copy.deepcopy(self.online_proj)\n",
    "        for p in self.target_encoder.parameters(): p.requires_grad = False\n",
    "        for p in self.target_proj.parameters():    p.requires_grad = False\n",
    "\n",
    "        self.tau_base = float(tau_base)  # base EMA momentum\n",
    "        self.tau = self.tau_base         # will be scheduled\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ema_update(self):\n",
    "        # target = tau * target + (1 - tau) * online\n",
    "        for o, t in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n",
    "            t.data.mul_(self.tau).add_(o.data, alpha=(1.0 - self.tau))\n",
    "        for o, t in zip(self.online_proj.parameters(), self.target_proj.parameters()):\n",
    "            t.data.mul_(self.tau).add_(o.data, alpha=(1.0 - self.tau))\n",
    "\n",
    "    def forward(self, v1, v2):\n",
    "        # Online branch\n",
    "        f1 = self.online_encoder(v1); z1 = self.online_proj(f1); p1 = self.predictor(z1)\n",
    "        f2 = self.online_encoder(v2); z2 = self.online_proj(f2); p2 = self.predictor(z2)\n",
    "        # Target branch (no grad)\n",
    "        with torch.no_grad():\n",
    "            t1 = self.target_proj(self.target_encoder(v1))\n",
    "            t2 = self.target_proj(self.target_encoder(v2))\n",
    "        # cosine loss (0 is best)\n",
    "        def cos_loss(p, z):\n",
    "            p = F.normalize(p, dim=1); z = F.normalize(z, dim=1)\n",
    "            return 2.0 - 2.0 * (p * z).sum(dim=1).mean()\n",
    "        loss = 0.5 * cos_loss(p1, t2) + 0.5 * cos_loss(p2, t1)\n",
    "        return loss\n",
    "\n",
    "# ---------------- Build unlabeled dataset ----------------\n",
    "# Uses your preloaded train set: frames already letterboxed & normalized to [-1,1]\n",
    "ssl_base = PreloadedNPZFrameDataset(TRAIN_DIR, train_files, binary=True, out_size=IMAGE_SIZE)\n",
    "ssl_ds   = SSLPairDataset(ssl_base, transform=ssl_transform)\n",
    "\n",
    "# ---------------- Hyperparams ----------------\n",
    "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SSL_BATCH    = 128\n",
    "SSL_EPOCHS   = 30\n",
    "LR_BASE      = 0.05\n",
    "WEIGHT_DEC   = 1e-4\n",
    "\n",
    "# Early stopping / checkpoints\n",
    "PATIENCE     = 7\n",
    "MIN_DELTA    = 1e-4\n",
    "SAVE_DIR     = \"D:/acouslic-ai-cse4622/saved_weights\"\n",
    "ENC_BEST     = os.path.join(SAVE_DIR, \"byol_encoder_best.pth\")\n",
    "FULL_BEST    = os.path.join(SAVE_DIR, \"byol_full_best.pth\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "ssl_loader = DataLoader(\n",
    "    ssl_ds, batch_size=SSL_BATCH, shuffle=True,\n",
    "    num_workers=0, pin_memory=True, drop_last=True\n",
    ")\n",
    "\n",
    "byol = BYOL(imagenet_init=True, tau_base=0.996).to(DEVICE)\n",
    "opt   = SGD(byol.parameters(), lr=LR_BASE, momentum=0.9, weight_decay=WEIGHT_DEC)\n",
    "sched = CosineAnnealingLR(opt, T_max=SSL_EPOCHS)\n",
    "scaler = amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "# Cosine schedule for EMA tau over total steps: tau -> closer to 1\n",
    "total_steps = SSL_EPOCHS * len(ssl_loader)\n",
    "cur_step = 0\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(1, SSL_EPOCHS+1):\n",
    "    byol.train()\n",
    "    running = 0.0\n",
    "    num_seen = 0\n",
    "\n",
    "    for v1, v2 in tqdm(ssl_loader, desc=f\"BYOL pretrain {epoch}/{SSL_EPOCHS}\"):\n",
    "        v1 = v1.to(DEVICE, non_blocking=True).float()\n",
    "        v2 = v2.to(DEVICE, non_blocking=True).float()\n",
    "\n",
    "        # Update EMA momentum (tau) with cosine schedule\n",
    "        if total_steps > 0:\n",
    "            # tau = 1 - (1 - tau_base) * (cos(pi * t/T) + 1)/2\n",
    "            cos_term = (1 + math.cos(math.pi * cur_step / total_steps)) / 2.0\n",
    "            byol.tau = 1.0 - (1.0 - byol.tau_base) * cos_term\n",
    "        cur_step += 1\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
    "            loss = byol(v1, v2)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        # EMA update AFTER optimizer step\n",
    "        with torch.no_grad():\n",
    "            byol.ema_update()\n",
    "\n",
    "        running += loss.item() * v1.size(0)\n",
    "        num_seen += v1.size(0)\n",
    "\n",
    "    sched.step()\n",
    "    avg_loss = running / max(1, num_seen)\n",
    "    print(f\"Epoch {epoch}: BYOL loss {avg_loss:.4f} (lower is better; 0 is ideal)\")\n",
    "\n",
    "    # Early stopping on best (lower) loss\n",
    "    if (best_loss - avg_loss) > MIN_DELTA:\n",
    "        best_loss = avg_loss\n",
    "        best_epoch = epoch\n",
    "        epochs_no_improve = 0\n",
    "        # Save best encoder and full checkpoint\n",
    "        torch.save(byol.online_encoder.state_dict(), ENC_BEST)\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": byol.state_dict(),\n",
    "            \"optimizer_state\": opt.state_dict(),\n",
    "            \"scheduler_state\": sched.state_dict(),\n",
    "            \"scaler_state\": scaler.state_dict(),\n",
    "            \"best_loss\": best_loss,\n",
    "        }, FULL_BEST)\n",
    "        print(f\"✅ Saved BEST (epoch {epoch}) | loss {best_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement ({epochs_no_improve}/{PATIENCE})\")\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"⏹ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(f\"Best epoch: {best_epoch} | Best BYOL loss: {best_loss:.4f}\")\n",
    "print(f\"Best encoder saved at: {ENC_BEST}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8418d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BYOL encoder. missing: ['fc.weight', 'fc.bias'] unexpected: []\n"
     ]
    }
   ],
   "source": [
    "model = FrameClassifier(num_classes=2).to(device)\n",
    "\n",
    "# --- load SimSiam encoder (from your SSL pretrain) ---\n",
    "SSL_ENC_PATH = \"D:/acouslic-ai-cse4622/saved_weights/byol_encoder_best.pth\"\n",
    "enc_state = torch.load(SSL_ENC_PATH, map_location=device)\n",
    "missing, unexpected = model.backbone.load_state_dict(enc_state, strict=False)\n",
    "print(\"Loaded BYOL encoder. missing:\", missing, \"unexpected:\", unexpected)\n",
    "# ------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "415f5bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\1507392109.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))  # ok\n"
     ]
    }
   ],
   "source": [
    "# loss (keep it simple first)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05).to(device)\n",
    "\n",
    "# head warmup: freeze backbone, train only the final FC\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.backbone.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "opt = torch.optim.AdamW(model.backbone.fc.parameters(), lr=LR_HEAD, weight_decay=WEIGHT_DEC)\n",
    "\n",
    "# (optional: modern AMP context later in the loop)\n",
    "from torch import amp\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))  # ok\n",
    "# and use: with amp.autocast(device_type=\"cuda\", enabled=(device==\"cuda\")):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b044f604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SimSiam encoder. missing: ['fc.weight', 'fc.bias'] unexpected: []\n"
     ]
    }
   ],
   "source": [
    "# load encoder-only checkpoint\n",
    "enc_state = torch.load(\"D:/acouslic-ai-cse4622/saved_weights/byol_encoder_best.pth\", map_location=device)\n",
    "\n",
    "# apply to your FrameClassifier backbone\n",
    "missing, unexpected = model.backbone.load_state_dict(enc_state, strict=False)\n",
    "print(\"Loaded SimSiam encoder. missing:\", missing, \"unexpected:\", unexpected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cf0dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_logits_targets(model, loader):\n",
    "    model.eval()\n",
    "    all_logits, all_targets = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True).float()\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_targets.append(y.cpu())\n",
    "    return torch.cat(all_logits), torch.cat(all_targets).numpy()\n",
    "\n",
    "def find_best_threshold(logits, targets, goal=\"f1\", target_precision=None):\n",
    "    probs = F.softmax(logits, dim=1)[:, 1].numpy()\n",
    "    y = np.array(targets)\n",
    "    best_t, best_score = 0.5, -1.0\n",
    "    for t in np.linspace(0.3, 0.9, 61):\n",
    "        yhat = (probs >= t).astype(int)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y, yhat, average=\"binary\", zero_division=0)\n",
    "        score = (r if (target_precision and p >= target_precision) else\n",
    "                 f1 if goal == \"f1\" else p)\n",
    "        if score > best_score:\n",
    "            best_score, best_t = score, t\n",
    "    return best_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc815ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 1/20: 100%|██████████| 346/346 [00:23<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | train loss 0.2385 | val acc 97.04% | P/R/F1 0.405/0.387/0.396 | thr* 0.89\n",
      "✅ Saved best model (val F1=0.396 @ thr=0.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 2/20: 100%|██████████| 346/346 [00:37<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 | train loss 0.1732 | val acc 96.17% | P/R/F1 0.382/0.854/0.528 | thr* 0.90\n",
      "✅ Saved best model (val F1=0.528 @ thr=0.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 3/20: 100%|██████████| 346/346 [00:36<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 | train loss 0.1415 | val acc 97.98% | P/R/F1 0.589/0.638/0.613 | thr* 0.87\n",
      "✅ Saved best model (val F1=0.613 @ thr=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 4/20: 100%|██████████| 346/346 [00:36<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 | train loss 0.1296 | val acc 97.18% | P/R/F1 0.461/0.736/0.567 | thr* 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 5/20: 100%|██████████| 346/346 [00:36<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 | train loss 0.1263 | val acc 97.97% | P/R/F1 0.586/0.640/0.612 | thr* 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 6/20: 100%|██████████| 346/346 [00:36<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 | train loss 0.1227 | val acc 97.76% | P/R/F1 0.546/0.630/0.585 | thr* 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 7/20: 100%|██████████| 346/346 [00:36<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 | train loss 0.1179 | val acc 95.73% | P/R/F1 0.358/0.887/0.510 | thr* 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8/20:   0%|          | 0/346 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22832\\4260613885.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
      "Train 8/20: 100%|██████████| 346/346 [00:36<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 | train loss 0.1155 | val acc 96.49% | P/R/F1 0.407/0.867/0.554 | thr* 0.90\n",
      "⏹ Early stopping.\n",
      "Best F1: 0.613 | Weights saved to: D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_BYOL.pth\n"
     ]
    }
   ],
   "source": [
    "best_metric = -1.0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # unfreeze backbone after warmup epoch 1\n",
    "    if epoch == 2 and any(not p.requires_grad for p in model.backbone.parameters()):\n",
    "        for p in model.backbone.parameters():\n",
    "            p.requires_grad = True\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=LR_ALL, weight_decay=WEIGHT_DEC)\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\"):\n",
    "        x = x.to(device, non_blocking=True).float()\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_ds)\n",
    "\n",
    "    # validation: pick threshold this epoch\n",
    "    val_logits, val_targets = collect_logits_targets(model, val_loader)\n",
    "    t_star = find_best_threshold(val_logits, val_targets, goal=\"f1\")  # or target_precision=0.80\n",
    "\n",
    "    probs = F.softmax(val_logits, dim=1)[:, 1].numpy()\n",
    "    pred  = (probs >= t_star).astype(int)\n",
    "\n",
    "    p, r, f1, _ = precision_recall_fscore_support(val_targets, pred, average=\"binary\", zero_division=0)\n",
    "    acc = (pred == val_targets).mean()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch} | train loss {train_loss:.4f} | val acc {acc*100:.2f}% | P/R/F1 {p:.3f}/{r:.3f}/{f1:.3f} | thr* {t_star:.2f}\")\n",
    "\n",
    "    # Save the best by F1 (positive class)\n",
    "    metric = f1\n",
    "    if metric > best_metric:\n",
    "        best_metric = metric\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"✅ Saved best model (val F1={best_metric:.3f} @ thr={t_star:.2f})\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"⏹ Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(f\"Best F1: {best_metric:.3f} | Weights saved to: {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "939ca609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 45 cases (tolerance=±3)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:43<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Summary ======\n",
      "Correct best-frame picks: 38/45 (84.4%)\n",
      "(tolerance = ±3, MA=9, topk=3, thresh=0.87)\n",
      "d42fb920-5df1-4341-93df-480c17355e44.npz: best= 803  prob=0.948  dist_to_pos=  0  HIT\n",
      "d5471cfd-6090-4d42-9a95-67ccbfbf612e.npz: best= 179  prob=0.936  dist_to_pos=  0  HIT\n",
      "d571d4e1-ff80-44b9-a481-07961c6a1208.npz: best=  47  prob=0.963  dist_to_pos=  0  HIT\n",
      "d5c3cfee-53ac-4021-8c1b-098c189f630e.npz: best= 623  prob=0.953  dist_to_pos=  0  HIT\n",
      "d5f8c859-de93-4a50-b324-1ae4ad0267d4.npz: best=  68  prob=0.948  dist_to_pos=  0  HIT\n",
      "d624338f-d09b-4bda-bbc3-3fa417015d6b.npz: best=  77  prob=0.982  dist_to_pos=  0  HIT\n",
      "d77b6ece-da17-4f88-818c-0c7340b3e54f.npz: best=  58  prob=0.976  dist_to_pos=  0  HIT\n",
      "d812091a-3635-4d51-9290-6adb3aa8681e.npz: best=  35  prob=0.925  dist_to_pos=  0  HIT\n",
      "d8c3665a-4dc3-40ce-b716-f30aab365332.npz: best= 179  prob=0.728  dist_to_pos=412  MISS\n",
      "db9d468d-cb20-4d5e-b059-31728f5950e6.npz: best= 333  prob=0.973  dist_to_pos=  0  HIT\n",
      "dc0cbbdf-e4bb-4de5-958a-10576129e440.npz: best=  50  prob=0.983  dist_to_pos=  0  HIT\n",
      "dc381d50-124d-4bc8-b504-9c9c3a3ae697.npz: best=  48  prob=0.989  dist_to_pos=  0  HIT\n",
      "dcdcb9a4-fec7-45a2-b2b7-a282f963c551.npz: best= 622  prob=0.940  dist_to_pos=559  MISS\n",
      "de35b365-6308-4974-b2fc-976e26584810.npz: best= 648  prob=0.853  dist_to_pos=  2  HIT\n",
      "de45de1a-2482-4024-ac8b-c18c4834b379.npz: best=  45  prob=0.688  dist_to_pos=  1  HIT\n",
      "de93dac8-41e0-4b03-946e-0accda6010af.npz: best= 804  prob=0.968  dist_to_pos=602  MISS\n",
      "de964751-ec9d-4c53-9da3-9d7f200987b1.npz: best=  36  prob=0.982  dist_to_pos=  0  HIT\n",
      "decd2d84-79a2-4239-b802-5afdf318e7e6.npz: best= 639  prob=0.953  dist_to_pos=  0  HIT\n",
      "e3670fa9-574c-4fbc-89af-f69aad63696d.npz: best= 317  prob=0.991  dist_to_pos=  0  HIT\n",
      "e5053a72-46f6-496d-8252-c8b531b5039b.npz: best= 209  prob=0.838  dist_to_pos=163  MISS\n",
      "e5a2d914-a35c-4207-9bc8-5e5cee7dbfba.npz: best= 474  prob=0.960  dist_to_pos=  0  HIT\n",
      "e608e364-6898-442c-be0f-aea8d7735c15.npz: best=  53  prob=0.979  dist_to_pos=  0  HIT\n",
      "e9025780-a9bb-4300-be4e-fb220e824646.npz: best= 206  prob=0.987  dist_to_pos=  0  HIT\n",
      "e9043ff5-f8a4-4095-bc44-26232e1be011.npz: best=  18  prob=0.951  dist_to_pos=  0  HIT\n",
      "ea2a8fbf-f7fe-43f4-9e0d-1da0ae9b1a0c.npz: best= 311  prob=0.919  dist_to_pos=  0  HIT\n",
      "ea724ff0-9990-4557-ab53-16f2fe1f1c8f.npz: best=  53  prob=0.963  dist_to_pos=  0  HIT\n",
      "ea86047a-bae4-464b-a2ed-015935bebb2a.npz: best=  65  prob=0.988  dist_to_pos=  0  HIT\n",
      "ebadcfcb-a682-4493-8502-2adc194bba8c.npz: best= 470  prob=0.971  dist_to_pos=  0  HIT\n",
      "ec65aa35-d54c-44da-80a4-883f631c345e.npz: best= 174  prob=0.875  dist_to_pos=141  MISS\n",
      "ee2e6220-b2f3-4c8e-9c85-f04ed0a6b6f7.npz: best= 493  prob=0.951  dist_to_pos=  0  HIT\n",
      "eee8da44-8db7-4c9e-b52d-b6d461158a4e.npz: best= 625  prob=0.985  dist_to_pos=  0  HIT\n",
      "f1fcabfc-f998-44c7-8420-c7a5ae5aaab7.npz: best=  53  prob=0.458  dist_to_pos=  2  HIT\n",
      "f256d725-9b06-4a88-a6b5-f9eee0f050f4.npz: best=  45  prob=0.928  dist_to_pos=  0  HIT\n",
      "f4488c3c-556e-43bd-95f9-ae4cbb7c7093.npz: best= 635  prob=0.743  dist_to_pos=121  MISS\n",
      "f4bebd1e-d3ca-4186-902a-2b6ef9391060.npz: best=  44  prob=0.919  dist_to_pos=  0  HIT\n",
      "f5611c30-d04b-4691-9bd6-1e6de392a63c.npz: best=  11  prob=0.976  dist_to_pos= 54  MISS\n",
      "f5a702f0-d759-4b53-8215-462e8145e638.npz: best= 168  prob=0.905  dist_to_pos=  0  HIT\n",
      "f5e853b1-9465-40b0-a246-7d3f6cb94de7.npz: best= 476  prob=0.964  dist_to_pos=  0  HIT\n",
      "f5e97e20-ad47-46e4-bf35-3f0c01ff51d0.npz: best=  86  prob=0.944  dist_to_pos=  0  HIT\n",
      "f8039e25-4652-440c-9476-b425f3fccb22.npz: best= 344  prob=0.923  dist_to_pos=  0  HIT\n",
      "f9ba7ffd-bc66-4da6-b97d-1286d760a184.npz: best= 333  prob=0.982  dist_to_pos=  0  HIT\n",
      "fc167d1b-045a-4057-936d-4862644af1f3.npz: best=  88  prob=0.980  dist_to_pos=  0  HIT\n",
      "fc63df40-f6ca-4917-99ba-dbe4310a6d04.npz: best= 615  prob=0.970  dist_to_pos=  0  HIT\n",
      "fdfd752d-2d83-4452-a3ba-97a626676334.npz: best= 226  prob=0.883  dist_to_pos=  0  HIT\n",
      "fe236600-a41c-4d26-b4ea-6d3ff109cf41.npz: best= 285  prob=0.910  dist_to_pos=  0  HIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, torch\n",
    "import torch.nn.functional as F\n",
    "from torch import amp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Config (edit these)\n",
    "# -----------------------------\n",
    "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_PATH  = \"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_BYOL.pth\"\n",
    "TEST_DIR    = \"D:/dataset/converted_classifier_npz_compact\"   # full 840-frame npz files\n",
    "START_IDX   = 255   # where your test split starts\n",
    "NUM_CASES   = 45\n",
    "IMAGE_SIZE  = 224\n",
    "MA_WINDOW   = 9 # temporal smoothing (moving average)\n",
    "TOPK        = 3     # use top-1 for \"best frame\"\n",
    "THRESH      = 0.87  # or e.g. 0.6 to require minimum smoothed prob\n",
    "TOLERANCE   = 3     # 0 = exact frame; try 3 for ±3 frames\n",
    "\n",
    "# -----------------------------\n",
    "# Utils (match your training preprocessing)\n",
    "# -----------------------------\n",
    "def letterbox_to_square_tensor(x: torch.Tensor, size=IMAGE_SIZE) -> torch.Tensor:\n",
    "    \"\"\"x: (B,1,H,W) or (1,H,W) in [0,1] -> square pad -> resize to (..,1,size,size)\"\"\"\n",
    "    is_batched = (x.dim() == 4)\n",
    "    if not is_batched: x = x.unsqueeze(0)\n",
    "    _, _, H, W = x.shape\n",
    "    s = max(H, W)\n",
    "    pad_h = (s - H) // 2\n",
    "    pad_w = (s - W) // 2\n",
    "    x = F.pad(x, (pad_w, s-W-pad_w, pad_h, s-H-pad_h))\n",
    "    x = F.interpolate(x, size=(size, size), mode=\"bilinear\", align_corners=False)\n",
    "    return x if is_batched else x.squeeze(0)\n",
    "\n",
    "def moving_average(a: np.ndarray, w: int = 7):\n",
    "    if w <= 1: return a\n",
    "    k = np.ones(w, dtype=np.float32) / w\n",
    "    return np.convolve(a, k, mode=\"same\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_over_frames(npz_path, model, batch_size=128):\n",
    "    d = np.load(npz_path, mmap_mode=\"r\")\n",
    "    frames = d[\"image\"]  # (T,H,W) uint8\n",
    "    Tn = len(frames)\n",
    "    probs = np.zeros(Tn, dtype=np.float32)\n",
    "    off = 0\n",
    "    while off < Tn:\n",
    "        chunk = frames[off:off+batch_size]\n",
    "        x = torch.from_numpy(chunk).unsqueeze(1).float() / 255.0      # (B,1,H,W) [0,1]\n",
    "        x = letterbox_to_square_tensor(x, size=IMAGE_SIZE)            # (B,1,S,S)\n",
    "        x = (x - 0.5) / 0.5                                           # [-1,1]\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(x)\n",
    "            p = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        probs[off:off+len(p)] = p\n",
    "        off += len(p)\n",
    "    return probs\n",
    "\n",
    "@torch.no_grad()\n",
    "def pick_best_frame(npz_path, model, ma_window=7, topk=1, thresh=None):\n",
    "    \"\"\"Returns best_idx (int), best_score (float), idx_topk (np.ndarray), raw_probs, smoothed_probs.\"\"\"\n",
    "    probs = predict_probs_over_frames(npz_path, model)\n",
    "    sm = moving_average(probs, w=ma_window)\n",
    "    idx_sorted = np.argsort(-sm)\n",
    "    idx_topk = idx_sorted[:topk]\n",
    "    if thresh is not None:\n",
    "        idx_topk = np.array([i for i in idx_topk if sm[i] >= thresh], dtype=int)\n",
    "        if len(idx_topk) == 0:\n",
    "            idx_topk = np.array([int(np.argmax(sm))], dtype=int)\n",
    "    best_idx = int(idx_topk[0])\n",
    "    best_score = float(sm[best_idx])\n",
    "    return best_idx, best_score, idx_topk, probs, sm\n",
    "\n",
    "def load_binary_labels(npz_path):\n",
    "    y = np.load(npz_path, mmap_mode=\"r\")[\"label\"].astype(np.int64)\n",
    "    y[y == 2] = 1\n",
    "    return y\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "model = FrameClassifier(num_classes=2).to(DEVICE)\n",
    "ckpt = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "state = ckpt.get(\"model_state\", ckpt)  # support plain state_dict too\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# Pick 45 test files and evaluate\n",
    "# -----------------------------\n",
    "files = sorted([f for f in os.listdir(TEST_DIR) if f.endswith(\".npz\")])\n",
    "test_files = files[START_IDX:START_IDX+NUM_CASES]\n",
    "assert len(test_files) > 0, \"No test files selected.\"\n",
    "\n",
    "correct = 0\n",
    "details = []\n",
    "\n",
    "print(f\"Evaluating {len(test_files)} cases (tolerance=±{TOLERANCE})...\\n\")\n",
    "for f in tqdm(test_files):\n",
    "    path = os.path.join(TEST_DIR, f)\n",
    "    y = load_binary_labels(path)\n",
    "    pos_idx = np.where(y == 1)[0]  # ground truth positive frames\n",
    "\n",
    "    best_idx, best_score, idx_topk, probs, sm = pick_best_frame(\n",
    "        path, model, ma_window=MA_WINDOW, topk=TOPK, thresh=THRESH\n",
    "    )\n",
    "\n",
    "    if len(pos_idx) == 0:\n",
    "        hit = (y[best_idx] == 0)  # no positives: \"correct\" if best is background\n",
    "        dist = 0\n",
    "    else:\n",
    "        # exact or ±tolerance match\n",
    "        dist = int(np.min(np.abs(pos_idx - best_idx)))\n",
    "        hit = (dist <= TOLERANCE)\n",
    "\n",
    "    correct += int(hit)\n",
    "    details.append((f, best_idx, best_score, dist, hit))\n",
    "\n",
    "# -----------------------------\n",
    "# Summary\n",
    "# -----------------------------\n",
    "print(\"\\n====== Summary ======\")\n",
    "print(f\"Correct best-frame picks: {correct}/{len(test_files)} ({100.0*correct/len(test_files):.1f}%)\")\n",
    "print(f\"(tolerance = ±{TOLERANCE}, MA={MA_WINDOW}, topk={TOPK}, thresh={THRESH})\")\n",
    "\n",
    "# Optional: show a few per-case lines\n",
    "for f, bi, bs, d, h in details[:45]:\n",
    "    print(f\"{f}: best={bi:4d}  prob={bs:.3f}  dist_to_pos={d:3d}  {'HIT' if h else 'MISS'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1eb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 45 cases (plateau: high=0.9, low=0.8, min_run=5, MA=11)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:43<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Summary ======\n",
      "Top-1 accuracy @ tol=±0: 80.0%\n",
      "Top-1 accuracy @ tol=±3: 84.4%\n",
      "Top-1 accuracy @ tol=±5: 84.4%\n",
      "(MA=11, plateau high=0.9, low=0.8, min_run=5, allow_none=False)\n",
      "d42fb920-5df1-4341-93df-480c17355e44.npz: best= 801  prob=0.920  dist_to_pos=  0  HIT\n",
      "d5471cfd-6090-4d42-9a95-67ccbfbf612e.npz: best=  45  prob=0.950  dist_to_pos=  0  HIT\n",
      "d571d4e1-ff80-44b9-a481-07961c6a1208.npz: best=  49  prob=0.934  dist_to_pos=  0  HIT\n",
      "d5c3cfee-53ac-4021-8c1b-098c189f630e.npz: best= 168  prob=0.959  dist_to_pos=  0  HIT\n",
      "d5f8c859-de93-4a50-b324-1ae4ad0267d4.npz: best=  70  prob=0.956  dist_to_pos=  0  HIT\n",
      "d624338f-d09b-4bda-bbc3-3fa417015d6b.npz: best=  72  prob=0.967  dist_to_pos=  0  HIT\n",
      "d77b6ece-da17-4f88-818c-0c7340b3e54f.npz: best=  57  prob=0.889  dist_to_pos=  0  HIT\n",
      "d812091a-3635-4d51-9290-6adb3aa8681e.npz: best=  35  prob=0.927  dist_to_pos=  0  HIT\n",
      "d8c3665a-4dc3-40ce-b716-f30aab365332.npz: best= 174  prob=0.622  dist_to_pos=417  MISS\n",
      "db9d468d-cb20-4d5e-b059-31728f5950e6.npz: best= 335  prob=0.974  dist_to_pos=  0  HIT\n",
      "dc0cbbdf-e4bb-4de5-958a-10576129e440.npz: best=  49  prob=0.981  dist_to_pos=  0  HIT\n",
      "dc381d50-124d-4bc8-b504-9c9c3a3ae697.npz: best= 180  prob=0.965  dist_to_pos=  0  HIT\n",
      "dcdcb9a4-fec7-45a2-b2b7-a282f963c551.npz: best= 625  prob=0.955  dist_to_pos=562  MISS\n",
      "de35b365-6308-4974-b2fc-976e26584810.npz: best= 649  prob=0.506  dist_to_pos=  1  MISS\n",
      "de45de1a-2482-4024-ac8b-c18c4834b379.npz: best=  50  prob=0.963  dist_to_pos=  0  HIT\n",
      "de93dac8-41e0-4b03-946e-0accda6010af.npz: best= 803  prob=0.837  dist_to_pos=601  MISS\n",
      "de964751-ec9d-4c53-9da3-9d7f200987b1.npz: best=  34  prob=0.951  dist_to_pos=  0  HIT\n",
      "decd2d84-79a2-4239-b802-5afdf318e7e6.npz: best= 175  prob=0.934  dist_to_pos=  0  HIT\n",
      "e3670fa9-574c-4fbc-89af-f69aad63696d.npz: best= 318  prob=0.977  dist_to_pos=  0  HIT\n",
      "e5053a72-46f6-496d-8252-c8b531b5039b.npz: best= 207  prob=0.562  dist_to_pos=161  MISS\n",
      "e5a2d914-a35c-4207-9bc8-5e5cee7dbfba.npz: best= 471  prob=0.931  dist_to_pos=  0  HIT\n",
      "e608e364-6898-442c-be0f-aea8d7735c15.npz: best=  50  prob=0.957  dist_to_pos=  0  HIT\n",
      "e9025780-a9bb-4300-be4e-fb220e824646.npz: best=  73  prob=0.968  dist_to_pos=  0  HIT\n",
      "e9043ff5-f8a4-4095-bc44-26232e1be011.npz: best=  18  prob=0.967  dist_to_pos=  0  HIT\n",
      "ea2a8fbf-f7fe-43f4-9e0d-1da0ae9b1a0c.npz: best= 308  prob=0.928  dist_to_pos=  0  HIT\n",
      "ea724ff0-9990-4557-ab53-16f2fe1f1c8f.npz: best=  55  prob=0.976  dist_to_pos=  0  HIT\n",
      "ea86047a-bae4-464b-a2ed-015935bebb2a.npz: best=  64  prob=0.973  dist_to_pos=  0  HIT\n",
      "ebadcfcb-a682-4493-8502-2adc194bba8c.npz: best= 470  prob=0.980  dist_to_pos=  0  HIT\n",
      "ec65aa35-d54c-44da-80a4-883f631c345e.npz: best=  34  prob=0.888  dist_to_pos=  1  MISS\n",
      "ee2e6220-b2f3-4c8e-9c85-f04ed0a6b6f7.npz: best= 484  prob=0.954  dist_to_pos=  0  HIT\n",
      "eee8da44-8db7-4c9e-b52d-b6d461158a4e.npz: best= 625  prob=0.963  dist_to_pos=  0  HIT\n",
      "f1fcabfc-f998-44c7-8420-c7a5ae5aaab7.npz: best= 626  prob=0.677  dist_to_pos=571  MISS\n",
      "f256d725-9b06-4a88-a6b5-f9eee0f050f4.npz: best= 187  prob=0.934  dist_to_pos=  0  HIT\n",
      "f4488c3c-556e-43bd-95f9-ae4cbb7c7093.npz: best= 635  prob=0.858  dist_to_pos=121  MISS\n",
      "f4bebd1e-d3ca-4186-902a-2b6ef9391060.npz: best=  45  prob=0.939  dist_to_pos=  0  HIT\n",
      "f5611c30-d04b-4691-9bd6-1e6de392a63c.npz: best= 596  prob=0.936  dist_to_pos=375  MISS\n",
      "f5a702f0-d759-4b53-8215-462e8145e638.npz: best= 167  prob=0.888  dist_to_pos=  0  HIT\n",
      "f5e853b1-9465-40b0-a246-7d3f6cb94de7.npz: best=   8  prob=0.956  dist_to_pos=  0  HIT\n",
      "f5e97e20-ad47-46e4-bf35-3f0c01ff51d0.npz: best=  85  prob=0.944  dist_to_pos=  0  HIT\n",
      "f8039e25-4652-440c-9476-b425f3fccb22.npz: best=  61  prob=0.917  dist_to_pos=  0  HIT\n",
      "f9ba7ffd-bc66-4da6-b97d-1286d760a184.npz: best= 336  prob=0.964  dist_to_pos=  0  HIT\n",
      "fc167d1b-045a-4057-936d-4862644af1f3.npz: best=  80  prob=0.944  dist_to_pos=  0  HIT\n",
      "fc63df40-f6ca-4917-99ba-dbe4310a6d04.npz: best= 615  prob=0.968  dist_to_pos=  0  HIT\n",
      "fdfd752d-2d83-4452-a3ba-97a626676334.npz: best=  34  prob=0.852  dist_to_pos=  0  HIT\n",
      "fe236600-a41c-4d26-b4ea-6d3ff109cf41.npz: best= 288  prob=0.926  dist_to_pos=  0  HIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, torch\n",
    "import torch.nn.functional as F\n",
    "from torch import amp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------------\n",
    "# Config (edit these)\n",
    "# ---------------------------------\n",
    "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_PATH   = \"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_afra.pth\"\n",
    "TEST_DIR     = \"D:/dataset/converted_classifier_npz_compact\"\n",
    "START_IDX    = 255\n",
    "NUM_CASES    = 45\n",
    "IMAGE_SIZE   = 224\n",
    "BATCH_SIZE   = 128\n",
    "MA_WINDOW    = 11      # try 9–11; 11 is a bit smoother\n",
    "# Hysteresis thresholds for plateau selection\n",
    "HYST_HIGH    = 0.90    # set to your val-tuned threshold\n",
    "HYST_LOW     = 0.80    # keep ~0.1 below HIGH\n",
    "MIN_RUN_LEN  = 5       # min consecutive frames to count as a plateau\n",
    "ALLOW_NONE   = False   # True -> return -1 if no frame passes thresholds\n",
    "TOPK         = 1       # kept for compatibility; plateau selection returns 1 index\n",
    "EVAL_TOLS    = (0, 3, 5)  # show accuracy at ±0/±3/±5\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ---------------------------------\n",
    "# Utils (match training preprocessing)\n",
    "# ---------------------------------\n",
    "def letterbox_to_square_tensor(x: torch.Tensor, size=IMAGE_SIZE) -> torch.Tensor:\n",
    "    \"\"\"x: (B,1,H,W) or (1,H,W) in [0,1] -> square pad -> resize to (..,1,size,size)\"\"\"\n",
    "    is_batched = (x.dim() == 4)\n",
    "    if not is_batched: x = x.unsqueeze(0)\n",
    "    _, _, H, W = x.shape\n",
    "    s = max(H, W)\n",
    "    pad_h = (s - H) // 2\n",
    "    pad_w = (s - W) // 2\n",
    "    x = F.pad(x, (pad_w, s - W - pad_w, pad_h, s - H - pad_h))  # L,R,T,B\n",
    "    x = F.interpolate(x, size=(size, size), mode=\"bilinear\", align_corners=False)\n",
    "    return x if is_batched else x.squeeze(0)\n",
    "\n",
    "def moving_average_safe(a: np.ndarray, w: int = 7) -> np.ndarray:\n",
    "    \"\"\"Edge-safe moving average using edge padding.\"\"\"\n",
    "    if w <= 1: return a\n",
    "    pad = w // 2\n",
    "    ap = np.pad(a, (pad, pad), mode=\"edge\")\n",
    "    k = np.ones(w, dtype=np.float32) / w\n",
    "    return np.convolve(ap, k, mode=\"valid\")\n",
    "\n",
    "def _segments_above_threshold(a: np.ndarray, low: float):\n",
    "    \"\"\"Return list of (start,end) inclusive segments where a >= low.\"\"\"\n",
    "    on = a >= low\n",
    "    segs = []\n",
    "    i, n = 0, len(a)\n",
    "    while i < n:\n",
    "        if not on[i]:\n",
    "            i += 1\n",
    "            continue\n",
    "        j = i\n",
    "        while j + 1 < n and on[j + 1]:\n",
    "            j += 1\n",
    "        segs.append((i, j))\n",
    "        i = j + 1\n",
    "    return segs\n",
    "\n",
    "def pick_best_index_from_plateaus(smoothed: np.ndarray,\n",
    "                                  high: float,\n",
    "                                  low: float,\n",
    "                                  min_len: int) -> int:\n",
    "    \"\"\"\n",
    "    Prefer sustained plateaus:\n",
    "      1) segments where smoothed >= low\n",
    "      2) keep those whose max >= high and length >= min_len\n",
    "      3) choose the one with highest peak (break ties by longer length)\n",
    "      4) return the segment center index\n",
    "    Fallback: argmax if none qualify.\n",
    "    \"\"\"\n",
    "    segs = _segments_above_threshold(smoothed, low)\n",
    "    cand = []\n",
    "    for (s, e) in segs:\n",
    "        seg = smoothed[s:e+1]\n",
    "        if seg.max() >= high and (e - s + 1) >= min_len:\n",
    "            cand.append((s, e, seg.max()))\n",
    "    if cand:\n",
    "        cand.sort(key=lambda t: (t[2], (t[1] - t[0] + 1)), reverse=True)\n",
    "        s, e, _ = cand[0]\n",
    "        return (s + e) // 2\n",
    "    return int(np.argmax(smoothed))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_over_frames(npz_path, model, batch_size=BATCH_SIZE):\n",
    "    d = np.load(npz_path, mmap_mode=\"r\")\n",
    "    frames = d[\"image\"]  # (T,H,W) uint8\n",
    "    Tn = len(frames)\n",
    "    probs = np.zeros(Tn, dtype=np.float32)\n",
    "    off = 0\n",
    "    while off < Tn:\n",
    "        chunk = frames[off:off+batch_size]\n",
    "        x = torch.from_numpy(chunk).unsqueeze(1).float() / 255.0      # (B,1,H,W) [0,1]\n",
    "        x = letterbox_to_square_tensor(x, size=IMAGE_SIZE)            # (B,1,S,S)\n",
    "        x = (x - 0.5) / 0.5                                           # [-1,1]\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(DEVICE == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            p = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        probs[off:off+len(p)] = p\n",
    "        off += len(p)\n",
    "    return probs\n",
    "\n",
    "@torch.no_grad()\n",
    "def pick_best_frame(npz_path, model,\n",
    "                    ma_window=MA_WINDOW,\n",
    "                    high=HYST_HIGH, low=HYST_LOW,\n",
    "                    min_run=MIN_RUN_LEN,\n",
    "                    allow_none=ALLOW_NONE):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      best_idx (int), best_score (float), raw_probs (np.ndarray), smoothed_probs (np.ndarray)\n",
    "      If allow_none and no plateau meets criteria, best_idx == -1\n",
    "    \"\"\"\n",
    "    probs = predict_probs_over_frames(npz_path, model)\n",
    "    sm = moving_average_safe(probs, w=ma_window)\n",
    "\n",
    "    best_idx = pick_best_index_from_plateaus(sm, high=high, low=low, min_len=min_run)\n",
    "\n",
    "    # Optionally allow \"no suitable frame\" if even argmax is below high\n",
    "    if allow_none and sm[best_idx] < high:\n",
    "        return -1, float(sm.max()), probs, sm\n",
    "\n",
    "    return int(best_idx), float(sm[best_idx]), probs, sm\n",
    "\n",
    "def load_binary_labels(npz_path):\n",
    "    y = np.load(npz_path, mmap_mode=\"r\")[\"label\"].astype(np.int64)\n",
    "    y[y == 2] = 1\n",
    "    return y\n",
    "\n",
    "# ---------------------------------\n",
    "# Load model\n",
    "# ---------------------------------\n",
    "model = FrameClassifier(num_classes=2).to(DEVICE)\n",
    "ckpt = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "state = ckpt.get(\"model_state\", ckpt)  # support plain state_dict too\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------------\n",
    "# Evaluate selected test files\n",
    "# ---------------------------------\n",
    "files = sorted([f for f in os.listdir(TEST_DIR) if f.endswith(\".npz\")])\n",
    "test_files = files[START_IDX:START_IDX+NUM_CASES]\n",
    "assert len(test_files) > 0, \"No test files selected.\"\n",
    "\n",
    "details = []  # (fname, best_idx, best_score, dist, hit@0, has_pos, bg_correct)\n",
    "\n",
    "print(f\"Evaluating {len(test_files)} cases (plateau: high={HYST_HIGH}, low={HYST_LOW}, min_run={MIN_RUN_LEN}, MA={MA_WINDOW})...\\n\")\n",
    "for f in tqdm(test_files):\n",
    "    path = os.path.join(TEST_DIR, f)\n",
    "    y = load_binary_labels(path)\n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    has_pos = (len(pos_idx) > 0)\n",
    "\n",
    "    best_idx, best_score, probs, sm = pick_best_frame(\n",
    "        path, model, ma_window=MA_WINDOW, high=HYST_HIGH, low=HYST_LOW, min_run=MIN_RUN_LEN, allow_none=ALLOW_NONE\n",
    "    )\n",
    "\n",
    "    if best_idx == -1:\n",
    "        # no suitable frame predicted\n",
    "        dist = 0\n",
    "        bg_correct = (not has_pos)  # correct only if truly no positive frames\n",
    "        hit0 = bg_correct\n",
    "    else:\n",
    "        if has_pos:\n",
    "            dist = int(np.min(np.abs(pos_idx - best_idx)))\n",
    "            hit0 = (dist <= 0)\n",
    "            bg_correct = False\n",
    "        else:\n",
    "            dist = 0\n",
    "            hit0 = (y[best_idx] == 0)\n",
    "            bg_correct = hit0\n",
    "\n",
    "    details.append((f, best_idx, best_score, dist, hit0, has_pos, bg_correct))\n",
    "\n",
    "# ---------------------------------\n",
    "# Summary\n",
    "# ---------------------------------\n",
    "print(\"\\n====== Summary ======\")\n",
    "for tol in EVAL_TOLS:\n",
    "    correct_t = 0\n",
    "    for _, _, _, dist, _, has_pos, bg_correct in details:\n",
    "        if has_pos:\n",
    "            correct_t += int(dist <= tol)\n",
    "        else:\n",
    "            correct_t += int(bg_correct)  # background-only sweeps handled separately\n",
    "    print(f\"Top-1 accuracy @ tol=±{tol}: {100.0*correct_t/len(details):.1f}%\")\n",
    "\n",
    "print(f\"(MA={MA_WINDOW}, plateau high={HYST_HIGH}, low={HYST_LOW}, min_run={MIN_RUN_LEN}, allow_none={ALLOW_NONE})\")\n",
    "\n",
    "# Show all cases\n",
    "for f, bi, bs, d, h0, _, _ in details:\n",
    "    tag = \"MISS\" if (d > 0) else \"HIT\"\n",
    "    print(f\"{f}: best={bi:4d}  prob={bs:.3f}  dist_to_pos={d:3d}  {tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2aa2c3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 45 cases (tolerance=±1)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:43<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Summary ======\n",
      "Correct best-frame picks: 36/45 (80.0%)\n",
      "(tolerance = ±1, MA=13, topk=1, thresh=0.9)\n",
      "d42fb920-5df1-4341-93df-480c17355e44.npz: best= 802  prob=0.904  dist_to_pos=  0  HIT\n",
      "d5471cfd-6090-4d42-9a95-67ccbfbf612e.npz: best=  46  prob=0.951  dist_to_pos=  0  HIT\n",
      "d571d4e1-ff80-44b9-a481-07961c6a1208.npz: best= 342  prob=0.932  dist_to_pos=  0  HIT\n",
      "d5c3cfee-53ac-4021-8c1b-098c189f630e.npz: best= 479  prob=0.944  dist_to_pos=  3  MISS\n",
      "d5f8c859-de93-4a50-b324-1ae4ad0267d4.npz: best=  69  prob=0.952  dist_to_pos=  0  HIT\n",
      "d624338f-d09b-4bda-bbc3-3fa417015d6b.npz: best=  69  prob=0.963  dist_to_pos=  0  HIT\n",
      "d77b6ece-da17-4f88-818c-0c7340b3e54f.npz: best=  57  prob=0.799  dist_to_pos=  0  HIT\n",
      "d812091a-3635-4d51-9290-6adb3aa8681e.npz: best=  37  prob=0.863  dist_to_pos=  0  HIT\n",
      "d8c3665a-4dc3-40ce-b716-f30aab365332.npz: best= 595  prob=0.642  dist_to_pos=  0  HIT\n",
      "db9d468d-cb20-4d5e-b059-31728f5950e6.npz: best= 335  prob=0.945  dist_to_pos=  0  HIT\n",
      "dc0cbbdf-e4bb-4de5-958a-10576129e440.npz: best=  50  prob=0.959  dist_to_pos=  0  HIT\n",
      "dc381d50-124d-4bc8-b504-9c9c3a3ae697.npz: best= 179  prob=0.954  dist_to_pos=  0  HIT\n",
      "dcdcb9a4-fec7-45a2-b2b7-a282f963c551.npz: best= 629  prob=0.956  dist_to_pos=566  MISS\n",
      "de35b365-6308-4974-b2fc-976e26584810.npz: best= 647  prob=0.424  dist_to_pos=  3  MISS\n",
      "de45de1a-2482-4024-ac8b-c18c4834b379.npz: best=  51  prob=0.839  dist_to_pos=  0  HIT\n",
      "de93dac8-41e0-4b03-946e-0accda6010af.npz: best= 198  prob=0.945  dist_to_pos=  0  HIT\n",
      "de964751-ec9d-4c53-9da3-9d7f200987b1.npz: best=  40  prob=0.963  dist_to_pos=  0  HIT\n",
      "decd2d84-79a2-4239-b802-5afdf318e7e6.npz: best= 177  prob=0.933  dist_to_pos=  0  HIT\n",
      "e3670fa9-574c-4fbc-89af-f69aad63696d.npz: best= 318  prob=0.959  dist_to_pos=  0  HIT\n",
      "e5053a72-46f6-496d-8252-c8b531b5039b.npz: best= 208  prob=0.556  dist_to_pos=162  MISS\n",
      "e5a2d914-a35c-4207-9bc8-5e5cee7dbfba.npz: best= 473  prob=0.961  dist_to_pos=  0  HIT\n",
      "e608e364-6898-442c-be0f-aea8d7735c15.npz: best=  51  prob=0.957  dist_to_pos=  0  HIT\n",
      "e9025780-a9bb-4300-be4e-fb220e824646.npz: best= 206  prob=0.963  dist_to_pos=  0  HIT\n",
      "e9043ff5-f8a4-4095-bc44-26232e1be011.npz: best= 474  prob=0.950  dist_to_pos=332  MISS\n",
      "ea2a8fbf-f7fe-43f4-9e0d-1da0ae9b1a0c.npz: best=  28  prob=0.739  dist_to_pos=  2  MISS\n",
      "ea724ff0-9990-4557-ab53-16f2fe1f1c8f.npz: best= 188  prob=0.962  dist_to_pos=  0  HIT\n",
      "ea86047a-bae4-464b-a2ed-015935bebb2a.npz: best=  62  prob=0.968  dist_to_pos=  0  HIT\n",
      "ebadcfcb-a682-4493-8502-2adc194bba8c.npz: best= 470  prob=0.957  dist_to_pos=  0  HIT\n",
      "ec65aa35-d54c-44da-80a4-883f631c345e.npz: best= 172  prob=0.781  dist_to_pos=139  MISS\n",
      "ee2e6220-b2f3-4c8e-9c85-f04ed0a6b6f7.npz: best= 487  prob=0.969  dist_to_pos=  0  HIT\n",
      "eee8da44-8db7-4c9e-b52d-b6d461158a4e.npz: best= 632  prob=0.966  dist_to_pos=  0  HIT\n",
      "f1fcabfc-f998-44c7-8420-c7a5ae5aaab7.npz: best=  54  prob=0.393  dist_to_pos=  1  HIT\n",
      "f256d725-9b06-4a88-a6b5-f9eee0f050f4.npz: best=  47  prob=0.946  dist_to_pos=  0  HIT\n",
      "f4488c3c-556e-43bd-95f9-ae4cbb7c7093.npz: best= 635  prob=0.732  dist_to_pos=121  MISS\n",
      "f4bebd1e-d3ca-4186-902a-2b6ef9391060.npz: best=  46  prob=0.933  dist_to_pos=  0  HIT\n",
      "f5611c30-d04b-4691-9bd6-1e6de392a63c.npz: best=  70  prob=0.744  dist_to_pos=  0  HIT\n",
      "f5a702f0-d759-4b53-8215-462e8145e638.npz: best= 146  prob=0.682  dist_to_pos= 18  MISS\n",
      "f5e853b1-9465-40b0-a246-7d3f6cb94de7.npz: best= 480  prob=0.959  dist_to_pos=  0  HIT\n",
      "f5e97e20-ad47-46e4-bf35-3f0c01ff51d0.npz: best=  86  prob=0.945  dist_to_pos=  0  HIT\n",
      "f8039e25-4652-440c-9476-b425f3fccb22.npz: best=  57  prob=0.952  dist_to_pos=  0  HIT\n",
      "f9ba7ffd-bc66-4da6-b97d-1286d760a184.npz: best= 330  prob=0.945  dist_to_pos=  0  HIT\n",
      "fc167d1b-045a-4057-936d-4862644af1f3.npz: best=  88  prob=0.969  dist_to_pos=  0  HIT\n",
      "fc63df40-f6ca-4917-99ba-dbe4310a6d04.npz: best= 609  prob=0.957  dist_to_pos=  0  HIT\n",
      "fdfd752d-2d83-4452-a3ba-97a626676334.npz: best= 343  prob=0.905  dist_to_pos=  0  HIT\n",
      "fe236600-a41c-4d26-b4ea-6d3ff109cf41.npz: best= 286  prob=0.898  dist_to_pos=  0  HIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, torch\n",
    "import torch.nn.functional as F\n",
    "from torch import amp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Config (edit these)\n",
    "# -----------------------------\n",
    "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_PATH  = \"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_anika.pth\"\n",
    "TEST_DIR    = \"D:/dataset/converted_classifier_npz_compact\"   # full 840-frame npz files\n",
    "START_IDX   = 255   # where your test split starts\n",
    "NUM_CASES   = 45\n",
    "IMAGE_SIZE  = 224\n",
    "MA_WINDOW   = 13    # temporal smoothing (moving average)\n",
    "TOPK        = 1     # use top-1 for \"best frame\"\n",
    "THRESH      = 0.90  # or e.g. 0.6 to require minimum smoothed prob\n",
    "TOLERANCE   = 1     # 0 = exact frame; try 3 for ±3 frames\n",
    "\n",
    "# -----------------------------\n",
    "# Utils (match your training preprocessing)\n",
    "# -----------------------------\n",
    "def letterbox_to_square_tensor(x: torch.Tensor, size=IMAGE_SIZE) -> torch.Tensor:\n",
    "    \"\"\"x: (B,1,H,W) or (1,H,W) in [0,1] -> square pad -> resize to (..,1,size,size)\"\"\"\n",
    "    is_batched = (x.dim() == 4)\n",
    "    if not is_batched: x = x.unsqueeze(0)\n",
    "    _, _, H, W = x.shape\n",
    "    s = max(H, W)\n",
    "    pad_h = (s - H) // 2\n",
    "    pad_w = (s - W) // 2\n",
    "    x = F.pad(x, (pad_w, s-W-pad_w, pad_h, s-H-pad_h))\n",
    "    x = F.interpolate(x, size=(size, size), mode=\"bilinear\", align_corners=False)\n",
    "    return x if is_batched else x.squeeze(0)\n",
    "\n",
    "def moving_average(a: np.ndarray, w: int = 7):\n",
    "    if w <= 1: return a\n",
    "    k = np.ones(w, dtype=np.float32) / w\n",
    "    return np.convolve(a, k, mode=\"same\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_over_frames(npz_path, model, batch_size=128):\n",
    "    d = np.load(npz_path, mmap_mode=\"r\")\n",
    "    frames = d[\"image\"]  # (T,H,W) uint8\n",
    "    Tn = len(frames)\n",
    "    probs = np.zeros(Tn, dtype=np.float32)\n",
    "    off = 0\n",
    "    while off < Tn:\n",
    "        chunk = frames[off:off+batch_size]\n",
    "        x = torch.from_numpy(chunk).unsqueeze(1).float() / 255.0      # (B,1,H,W) [0,1]\n",
    "        x = letterbox_to_square_tensor(x, size=IMAGE_SIZE)            # (B,1,S,S)\n",
    "        x = (x - 0.5) / 0.5                                           # [-1,1]\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(x)\n",
    "            p = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        probs[off:off+len(p)] = p\n",
    "        off += len(p)\n",
    "    return probs\n",
    "\n",
    "@torch.no_grad()\n",
    "def pick_best_frame(npz_path, model, ma_window=7, topk=1, thresh=None):\n",
    "    \"\"\"Returns best_idx (int), best_score (float), idx_topk (np.ndarray), raw_probs, smoothed_probs.\"\"\"\n",
    "    probs = predict_probs_over_frames(npz_path, model)\n",
    "    sm = moving_average(probs, w=ma_window)\n",
    "    idx_sorted = np.argsort(-sm)\n",
    "    idx_topk = idx_sorted[:topk]\n",
    "    if thresh is not None:\n",
    "        idx_topk = np.array([i for i in idx_topk if sm[i] >= thresh], dtype=int)\n",
    "        if len(idx_topk) == 0:\n",
    "            idx_topk = np.array([int(np.argmax(sm))], dtype=int)\n",
    "    best_idx = int(idx_topk[0])\n",
    "    best_score = float(sm[best_idx])\n",
    "    return best_idx, best_score, idx_topk, probs, sm\n",
    "\n",
    "def load_binary_labels(npz_path):\n",
    "    y = np.load(npz_path, mmap_mode=\"r\")[\"label\"].astype(np.int64)\n",
    "    y[y == 2] = 1\n",
    "    return y\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "model = FrameClassifier(num_classes=2).to(DEVICE)\n",
    "ckpt = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "state = ckpt.get(\"model_state\", ckpt)  # support plain state_dict too\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# Pick 45 test files and evaluate\n",
    "# -----------------------------\n",
    "files = sorted([f for f in os.listdir(TEST_DIR) if f.endswith(\".npz\")])\n",
    "test_files = files[START_IDX:START_IDX+NUM_CASES]\n",
    "assert len(test_files) > 0, \"No test files selected.\"\n",
    "\n",
    "correct = 0\n",
    "details = []\n",
    "\n",
    "print(f\"Evaluating {len(test_files)} cases (tolerance=±{TOLERANCE})...\\n\")\n",
    "for f in tqdm(test_files):\n",
    "    path = os.path.join(TEST_DIR, f)\n",
    "    y = load_binary_labels(path)\n",
    "    pos_idx = np.where(y == 1)[0]  # ground truth positive frames\n",
    "\n",
    "    best_idx, best_score, idx_topk, probs, sm = pick_best_frame(\n",
    "        path, model, ma_window=MA_WINDOW, topk=TOPK, thresh=THRESH\n",
    "    )\n",
    "\n",
    "    if len(pos_idx) == 0:\n",
    "        hit = (y[best_idx] == 0)  # no positives: \"correct\" if best is background\n",
    "        dist = 0\n",
    "    else:\n",
    "        # exact or ±tolerance match\n",
    "        dist = int(np.min(np.abs(pos_idx - best_idx)))\n",
    "        hit = (dist <= TOLERANCE)\n",
    "\n",
    "    correct += int(hit)\n",
    "    details.append((f, best_idx, best_score, dist, hit))\n",
    "\n",
    "# -----------------------------\n",
    "# Summary\n",
    "# -----------------------------\n",
    "print(\"\\n====== Summary ======\")\n",
    "print(f\"Correct best-frame picks: {correct}/{len(test_files)} ({100.0*correct/len(test_files):.1f}%)\")\n",
    "print(f\"(tolerance = ±{TOLERANCE}, MA={MA_WINDOW}, topk={TOPK}, thresh={THRESH})\")\n",
    "\n",
    "# Optional: show a few per-case lines\n",
    "for f, bi, bs, d, h in details[:45]:\n",
    "    print(f\"{f}: best={bi:4d}  prob={bs:.3f}  dist_to_pos={d:3d}  {'HIT' if h else 'MISS'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae533c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
