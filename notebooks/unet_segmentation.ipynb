{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eea498c",
   "metadata": {},
   "source": [
    "Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd0ba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 45)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, math, json, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import InterpolationMode as IM\n",
    "\n",
    "# root with your 80-frame .npz files\n",
    "NPZ_DIR = r\"D:/dataset/npz_80\"\n",
    "\n",
    "# fixed split as you requested\n",
    "all_npz = sorted([f for f in os.listdir(NPZ_DIR) if f.endswith(\".npz\")])\n",
    "train_files = all_npz[:210]\n",
    "val_files   = all_npz[210:255]\n",
    "\n",
    "len(train_files), len(val_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d683969",
   "metadata": {},
   "source": [
    "Utilities (letterbox resize + paired aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4867be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def letterbox_params(H:int, W:int, target_hw:Tuple[int,int]):\n",
    "    th, tw = target_hw\n",
    "    scale = min(th / H, tw / W)\n",
    "    nh, nw = int(round(H * scale)), int(round(W * scale))\n",
    "    pad_h = th - nh\n",
    "    pad_w = tw - nw\n",
    "    pad_top    = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left   = pad_w // 2\n",
    "    pad_right  = pad_w - pad_left\n",
    "    return nh, nw, scale, (pad_left, pad_right, pad_top, pad_bottom)\n",
    "\n",
    "def apply_letterbox(img_t: torch.Tensor, target_hw:Tuple[int,int]):\n",
    "    \"\"\"\n",
    "    img_t: (C,H,W) in [0,1]\n",
    "    returns (C,th,tw), meta (H,W, nh,nw, scale, pads)\n",
    "    \"\"\"\n",
    "    C, H, W = img_t.shape\n",
    "    nh, nw, scale, pads = letterbox_params(H, W, target_hw)\n",
    "    th, tw = target_hw\n",
    "    img_t = F.interpolate(img_t.unsqueeze(0), size=(nh, nw), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "    pl, pr, pt, pb = pads\n",
    "    img_t = F.pad(img_t, (pl, pr, pt, pb), value=0.0)\n",
    "    return img_t, (H, W, nh, nw, scale, pads)\n",
    "\n",
    "def undo_letterbox(mask_t: torch.Tensor, meta):\n",
    "    \"\"\"\n",
    "    mask_t: (1,th,tw) float/binary after letterbox\n",
    "    meta from apply_letterbox\n",
    "    returns (1,H,W) in original size (nearest)\n",
    "    \"\"\"\n",
    "    H, W, nh, nw, scale, (pl, pr, pt, pb) = meta\n",
    "    # remove padding\n",
    "    m = mask_t[..., pt:pt+nh, pl:pl+nw]\n",
    "    # resize back\n",
    "    m = F.interpolate(m, size=(H, W), mode=\"nearest\")\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4c7e0",
   "metadata": {},
   "source": [
    "Dataset (positive frames only, 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa3a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegPositiveNPZ2D(Dataset):\n",
    "    \"\"\"\n",
    "    Yields (img, mask, meta) for frames where label in {1,2}.\n",
    "    - img: (1, th, tw) normalized to [-1,1]\n",
    "    - mask: (1, th, tw) in {0,1}\n",
    "    - meta: dict with file, frame_idx, pixel_spacing, original HW, letterbox meta\n",
    "    \"\"\"\n",
    "    def __init__(self, npz_dir, files, target_hw=(288, 352), augment=True):\n",
    "        self.npz_dir   = npz_dir\n",
    "        self.files     = files\n",
    "        self.target_hw = target_hw\n",
    "        self.augment   = augment\n",
    "        self.items     = []  # (fname, frame_idx)\n",
    "\n",
    "        for f in files:\n",
    "            case = np.load(os.path.join(npz_dir, f), mmap_mode=\"r\")\n",
    "            labels = case[\"label\"].astype(np.int64)\n",
    "            pos = np.where((labels==1)|(labels==2))[0]\n",
    "            for i in pos:\n",
    "                self.items.append((f, int(i)))\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def _load_frame(self, case, idx):\n",
    "        img = case[\"image\"][idx].astype(np.float32)   # (H,W)\n",
    "        msk = case[\"mask\"][idx].astype(np.uint8)      # (H,W) values {0,1,2}\n",
    "        # per-frame min-max -> [0,1]\n",
    "        mn, mx = img.min(), img.max()\n",
    "        img = (img - mn) / (mx - mn + 1e-8)\n",
    "        # map {1,2} -> 1\n",
    "        msk = (msk > 0).astype(np.float32)\n",
    "        return img, msk\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname, i = self.items[idx]\n",
    "        case = np.load(os.path.join(self.npz_dir, fname), mmap_mode=\"r\")\n",
    "\n",
    "        img_np, msk_np = self._load_frame(case, i)\n",
    "        H, W = img_np.shape\n",
    "\n",
    "        # to torch\n",
    "        img_t = torch.from_numpy(img_np)[None, ...]  # (1,H,W)\n",
    "        msk_t = torch.from_numpy(msk_np)[None, ...]  # (1,H,W)\n",
    "\n",
    "        # --- paired augmentations (keep modest) ---\n",
    "        if self.augment:\n",
    "            # horizontal flip\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                img_t = torch.flip(img_t, dims=[2])\n",
    "                msk_t = torch.flip(msk_t, dims=[2])\n",
    "            # small random rotation (-15..15)\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                ang = (torch.rand(1).item() * 30.0) - 15.0\n",
    "                img_t = TF.rotate(img_t, ang, interpolation=IM.BILINEAR, fill=0.0)\n",
    "                msk_t = TF.rotate(msk_t, ang, interpolation=IM.NEAREST,  fill=0.0)\n",
    "            # slight noise\n",
    "            if torch.rand(1).item() < 0.25:\n",
    "                img_t = (img_t + 0.03*torch.randn_like(img_t)).clamp(0,1)\n",
    "\n",
    "        # letterbox to target\n",
    "        img_t, meta_lb = apply_letterbox(img_t, self.target_hw)   # (1,th,tw)\n",
    "        msk_t, _       = apply_letterbox(msk_t, self.target_hw)   # (1,th,tw)\n",
    "\n",
    "        # final normalize to [-1,1]\n",
    "        img_t = (img_t - 0.5)/0.5\n",
    "\n",
    "        meta = {\n",
    "            \"file\": fname,\n",
    "            \"frame_idx\": i,\n",
    "            \"pixel_spacing\": float(case[\"pixel_spacing\"]),\n",
    "            \"orig_hw\": (H, W),\n",
    "            \"lb_meta\": meta_lb,\n",
    "        }\n",
    "        return img_t.float(), msk_t.float(), meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ffcac",
   "metadata": {},
   "source": [
    "Small UNet (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9272857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_c, out_c))\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_c, in_c//2, 2, stride=2)\n",
    "        self.conv = DoubleConv(in_c, out_c)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        dh = skip.size(2) - x.size(2)\n",
    "        dw = skip.size(3) - x.size(3)\n",
    "        x = F.pad(x, [dw//2, dw-dw//2, dh//2, dh-dh//2])\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, base=32):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(in_channels, base)\n",
    "        self.d1  = Down(base, base*2)\n",
    "        self.d2  = Down(base*2, base*4)\n",
    "        self.d3  = Down(base*4, base*8)\n",
    "        self.bott= DoubleConv(base*8, base*16)\n",
    "        self.u3  = Up(base*16, base*8)\n",
    "        self.u2  = Up(base*8,  base*4)\n",
    "        self.u1  = Up(base*4,  base*2)\n",
    "        self.u0  = Up(base*2,  base)\n",
    "        self.out = nn.Conv2d(base, out_channels, 1)\n",
    "    def forward(self,x):\n",
    "        x0 = self.inc(x)\n",
    "        x1 = self.d1(x0)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(x2)\n",
    "        xb = self.bott(x3)\n",
    "        x  = self.u3(xb, x3)\n",
    "        x  = self.u2(x,  x2)\n",
    "        x  = self.u1(x,  x1)\n",
    "        x  = self.u0(x,  x0)\n",
    "        return self.out(x)  # logits (B,1,H,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c10e4",
   "metadata": {},
   "source": [
    "Loss & metric (Dice + BCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326884ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.bce_weight = bce_weight\n",
    "    def forward(self, logits, target):\n",
    "        bce = self.bce(logits, target)\n",
    "        p = torch.sigmoid(logits)\n",
    "        inter = (p*target).sum(dim=(1,2,3))\n",
    "        denom = p.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3)) + 1e-6\n",
    "        dice = 1 - (2*inter/denom).mean()\n",
    "        return self.bce_weight*bce + (1-self.bce_weight)*dice\n",
    "\n",
    "@torch.no_grad()\n",
    "def dice_from_logits(logits, target, thr=0.5):\n",
    "    p = (torch.sigmoid(logits) >= thr).float()\n",
    "    inter = (p*target).sum(dim=(1,2,3))\n",
    "    denom = p.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3)) + 1e-6\n",
    "    return (2*inter/denom).mean().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab37b8a",
   "metadata": {},
   "source": [
    "Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e0e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_hw = (288, 352)  # keep this modest for your GPU\n",
    "train_ds = SegPositiveNPZ2D(NPZ_DIR, train_files, target_hw=target_hw, augment=True)\n",
    "val_ds   = SegPositiveNPZ2D(NPZ_DIR, val_files,   target_hw=target_hw, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209842f",
   "metadata": {},
   "source": [
    "Train (AMP, early stop on val Dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703f6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class NPZSegDataset(Dataset):\n",
    "    def __init__(self, npz_dir, files, transform=None):\n",
    "        self.paths = [os.path.join(npz_dir, f) for f in files]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Pre-read only shapes using mmap, not entire arrays\n",
    "        self.index_map = []  # (file_idx, frame_idx)\n",
    "        for file_idx, path in enumerate(self.paths):\n",
    "            with np.load(path, mmap_mode=\"r\") as case:\n",
    "                n_frames = case[\"image\"].shape[0]\n",
    "                for frame_idx in range(n_frames):\n",
    "                    self.index_map.append((file_idx, frame_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx, frame_idx = self.index_map[idx]\n",
    "        path = self.paths[file_idx]\n",
    "\n",
    "        # Load only one frame with mmap\n",
    "        with np.load(path, mmap_mode=\"r\") as case:\n",
    "            img = case[\"image\"][frame_idx].astype(np.float32, copy=False)\n",
    "            msk = case[\"mask\"][frame_idx].astype(np.float32, copy=False)\n",
    "\n",
    "        # normalize per-frame\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "\n",
    "        img = torch.from_numpy(img).unsqueeze(0)  # (1,H,W)\n",
    "        msk = torch.from_numpy(msk).unsqueeze(0)  # (1,H,W)\n",
    "\n",
    "        # resize to 224x224\n",
    "        img = F.interpolate(img.unsqueeze(0), size=(224,224),\n",
    "                            mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        msk = F.interpolate(msk.unsqueeze(0), size=(224,224),\n",
    "                            mode=\"nearest\").squeeze(0)\n",
    "\n",
    "        # apply transforms (if any)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, msk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e8f0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# U-Net Model\n",
    "# ============================================================\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, base=32):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_channels, base)\n",
    "        self.enc2 = ConvBlock(base, base*2)\n",
    "        self.enc3 = ConvBlock(base*2, base*4)\n",
    "        self.enc4 = ConvBlock(base*4, base*8)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.bottleneck = ConvBlock(base*8, base*16)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(base*16, base*8, 2, stride=2)\n",
    "        self.dec4 = ConvBlock(base*16, base*8)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
    "        self.dec3 = ConvBlock(base*8, base*4)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
    "        self.dec2 = ConvBlock(base*4, base*2)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
    "        self.dec1 = ConvBlock(base*2, base)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(base, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        d4 = self.dec4(torch.cat([self.up4(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6000999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Loss (BCE + Dice)\n",
    "# ============================================================\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce = self.bce(logits, targets)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = (probs*targets).sum(dim=(2,3))*2 + self.smooth\n",
    "        den = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3)) + self.smooth\n",
    "        dice = 1 - (num/den).mean()\n",
    "        return bce + dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5014e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Training\n",
    "# ============================================================\n",
    "def train_one_epoch(model, loader, optimizer, scaler, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img, msk in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        img, msk = img.to(device), msk.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "            logits = model(img)\n",
    "            loss   = criterion(logits, msk)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()*img.size(0)\n",
    "\n",
    "    return total_loss/len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for img, msk in tqdm(loader, desc=\"Val\", leave=False):\n",
    "            img, msk = img.to(device), msk.to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "                logits = model(img)\n",
    "                loss   = criterion(logits, msk)\n",
    "            total_loss += loss.item()*img.size(0)\n",
    "\n",
    "    return total_loss/len(loader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac80727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7560\\1678355662.py:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/4200 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7560\\2068454317.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Val:   0%|          | 0/900 [00:00<?, ?it/s]                C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7560\\2068454317.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0538 | Val Loss: 0.9889\n",
      "✅ New best model saved!\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0232 | Val Loss: 0.9572\n",
      "✅ New best model saved!\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0100 | Val Loss: 0.9235\n",
      "✅ New best model saved!\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9970 | Val Loss: 0.9106\n",
      "✅ New best model saved!\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9812 | Val Loss: 0.9001\n",
      "✅ New best model saved!\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9633 | Val Loss: 0.8893\n",
      "✅ New best model saved!\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9388 | Val Loss: 0.8664\n",
      "✅ New best model saved!\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     val_loss   \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, device)\n\u001b[0;32m     46\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, loader, optimizer, scaler, criterion, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, msk \u001b[38;5;129;01min\u001b[39;00m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m     img, msk \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device), msk\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mNPZSegDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Load only one frame with mmap\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(path, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m case:\n\u001b[1;32m---> 36\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcase\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[frame_idx]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     msk \u001b[38;5;241m=\u001b[39m case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m][frame_idx]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# normalize per-frame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:258\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\numpy\\lib\\format.py:858\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    856\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[0;32m    857\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[1;32m--> 858\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    860\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\site-packages\\numpy\\lib\\format.py:993\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 993\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    994\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\zipfile.py:930\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 930\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    932\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\zipfile.py:1020\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1020\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch310\\lib\\zipfile.py:945\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[1;34m(self, newdata)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    npz_dir = \"D:/dataset/npz_80\"\n",
    "    all_files = sorted(os.listdir(npz_dir))\n",
    "    train_files = all_files[:210]\n",
    "    val_files   = all_files[210:255]\n",
    "\n",
    "    # augmentations (optional)\n",
    "    train_transform = T.Compose([\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomVerticalFlip(),\n",
    "    ])\n",
    "    val_transform = None\n",
    "\n",
    "    train_dataset = NPZSegDataset(npz_dir, train_files, transform=train_transform)\n",
    "    val_dataset   = NPZSegDataset(npz_dir, val_files, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    model = UNet2D(in_channels=1, out_channels=1, base=32).to(device)\n",
    "\n",
    "    criterion = BCEDiceLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=3, factor=0.5)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "    # ================================\n",
    "    # Early Stopping + Checkpointing\n",
    "    # ================================\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 5\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    n_epochs = 20\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print(f\"\\nEpoch {epoch}/{n_epochs}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, criterion, device)\n",
    "        val_loss   = validate(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"✅ New best model saved!\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epochs.\")\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹ Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    # Save last model anyway\n",
    "    torch.save(model.state_dict(), \"last_model.pth\")\n",
    "    print(\"Training finished. Best model saved as best_model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
