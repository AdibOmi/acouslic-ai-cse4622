{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fa286c",
   "metadata": {},
   "source": [
    "# Acouslic-AI: SimCLR Pretraining → Frame Classifier (Ultrasound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983fe4b",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9f13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.18\n",
      "Python: 3.10.18 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:08:55) [MSC v.1929 64 bit (AMD64)]\n",
      "PyTorch: 2.8.0+cu128\n",
      "Torchvision: 0.23.0+cu128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "!python --version\n",
    "import sys, torch, torchvision\n",
    "print('Python:', sys.version)\n",
    "print('PyTorch:', torch.__version__)\n",
    "print('Torchvision:', torchvision.__version__)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef259f6",
   "metadata": {},
   "source": [
    "## 1. Paths & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df98d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust these to your environment\n",
    "NPZ_DIR = \"D:/dataset/npz_80\"\n",
    "SIMCLR_SAVE = \"D:/acouslic-ai-cse4622/saved_weights/simclr_resnet50_ultrasound.pth\"\n",
    "CLS_SAVE = \"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\"\n",
    "\n",
    "# Splits (no leakage)\n",
    "TRAIN_FILES = slice(0, 210)   # first 210 npz for train\n",
    "VAL_FILES   = slice(210, 255) # next 45 npz for val (adjust if needed)\n",
    "\n",
    "SEED = 1337\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c4612",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d13cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, random, time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a60cd5",
   "metadata": {},
   "source": [
    "## 3. Dataset: `NPZFrameDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d584af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NPZFrameDataset(Dataset):\n",
    "    \"\"\"Loads frames from .npz files and returns (1×H×W) tensors resized to 224×224.\n",
    "    Labels are kept as 0/1 (2→1 as in your original pipeline).\n",
    "    \"\"\"\n",
    "    def __init__(self, npz_dir, files, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for f in files:\n",
    "            path = os.path.join(npz_dir, f)\n",
    "            case = np.load(path, mmap_mode='r')  # lazy read\n",
    "            images = case['image'].astype(np.float32)   # (F,H,W)\n",
    "            labels = case['label'].astype(np.int64)     # (F,)\n",
    "\n",
    "            # normalize [0,1] per sweep\n",
    "            images = (images - images.min()) / (images.max() - images.min() + 1e-8)\n",
    "            labels = labels.copy()\n",
    "            labels[labels == 2] = 1  # collapse suboptimal→present for 2-class\n",
    "\n",
    "            for img, lbl in zip(images, labels):\n",
    "                self.samples.append((img, int(lbl)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.samples[idx]\n",
    "\n",
    "        # (H,W) → (1,H,W)\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "\n",
    "        # resize to (1,224,224)\n",
    "        img = F.interpolate(img.unsqueeze(0),\n",
    "                            size=(224, 224),\n",
    "                            mode='bilinear',\n",
    "                            align_corners=False).squeeze(0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)   # tensor → tensor augmentations\n",
    "\n",
    "        return img, torch.tensor(lbl).long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5a978",
   "metadata": {},
   "source": [
    "## 4. Ultrasound-aware augmentations for SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d134df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpeckleNoise:\n",
    "    def __init__(self, sigma=0.08, p=0.5):\n",
    "        self.sigma, self.p = sigma, p\n",
    "    def __call__(self, x):\n",
    "        # x: tensor [1,H,W] in [0,1]\n",
    "        if random.random() < self.p:\n",
    "            noise = torch.randn_like(x) * self.sigma\n",
    "            x = x * (1.0 + noise)\n",
    "            x = x.clamp(0, 1)\n",
    "        return x\n",
    "\n",
    "class LineDropout:\n",
    "    \"\"\"Randomly zero out a few vertical scanlines (ultrasound-like).\"\"\"\n",
    "    def __init__(self, p=0.25, max_lines=5, max_width=2):\n",
    "        self.p, self.max_lines, self.max_width = p, max_lines, max_width\n",
    "    def __call__(self, x):\n",
    "        if random.random() >= self.p: return x\n",
    "        C, H, W = x.shape\n",
    "        k = random.randint(1, self.max_lines)\n",
    "        for _ in range(k):\n",
    "            col = random.randint(0, W-1)\n",
    "            w = random.randint(1, self.max_width)\n",
    "            x[:, :, max(0,col-w):min(W,col+w+1)] = 0.0\n",
    "        return x\n",
    "\n",
    "def get_simclr_transform():\n",
    "    return T.Compose([\n",
    "        T.RandomResizedCrop(224, scale=(0.6, 1.0), ratio=(0.9, 1.1)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=15),\n",
    "        T.RandomApply([T.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "        SpeckleNoise(sigma=0.08, p=0.5),\n",
    "        LineDropout(p=0.25, max_lines=5, max_width=2),\n",
    "        T.RandomApply([T.Lambda(lambda x: (x + 0.02*torch.randn_like(x)).clamp(0,1))], p=0.2),\n",
    "        T.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb5398",
   "metadata": {},
   "source": [
    "## 5. SimCLR two-view wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbc1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimCLRWrapper(Dataset):\n",
    "    \"\"\"Wraps a base dataset to emit two augmented views per sample.\"\"\"\n",
    "    def __init__(self, base: Dataset, aug_a, aug_b=None):\n",
    "        self.base = base\n",
    "        self.aug_a = aug_a\n",
    "        self.aug_b = aug_b if aug_b is not None else aug_a\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x, _ = self.base[idx]      # ignore label in pretraining\n",
    "        v1 = self.aug_a(x.clone())\n",
    "        v2 = self.aug_b(x.clone())\n",
    "        return v1, v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32cb2f",
   "metadata": {},
   "source": [
    "## 6. SimCLR encoder + projector (ResNet50 grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df971ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _resnet50_imagenet_grayscale():\n",
    "    # Handle torchvision API differences for weights arg\n",
    "    try:\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
    "        enc = models.resnet50(weights=weights)\n",
    "    except Exception:\n",
    "        enc = models.resnet50(pretrained=True)\n",
    "    enc.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    return enc\n",
    "\n",
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, proj_out=128):\n",
    "        super().__init__()\n",
    "        enc = _resnet50_imagenet_grayscale()\n",
    "        # keep up to global avgpool (remove final fc)\n",
    "        self.encoder = nn.Sequential(*list(enc.children())[:-1])  # [B,2048,1,1]\n",
    "        feat_dim = 2048\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, proj_out)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x).flatten(1)     # [B,2048]\n",
    "        z = self.projector(h)              # [B,proj_out]\n",
    "        z = F.normalize(z, dim=1)\n",
    "        return h, z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6edd0",
   "metadata": {},
   "source": [
    "## 7. NT-Xent (InfoNCE) loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33232d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(z1, z2, temperature=0.2):\n",
    "    z1 = F.normalize(z1, dim=1).to(torch.float32)\n",
    "    z2 = F.normalize(z2, dim=1).to(torch.float32)\n",
    "    N = z1.size(0)\n",
    "    z = torch.cat([z1, z2], dim=0)                 # [2N, D], fp32\n",
    "    sim = (z @ z.t()) / float(temperature)         # [2N, 2N], fp32\n",
    "    mask = torch.eye(2*N, device=z.device, dtype=torch.bool)\n",
    "    sim = sim.masked_fill(mask, float('-inf'))     # safe in fp32\n",
    "\n",
    "    pos_idx = torch.cat([torch.arange(N, 2*N, device=z.device),\n",
    "                         torch.arange(0, N, device=z.device)], dim=0)\n",
    "    labels = pos_idx\n",
    "    return F.cross_entropy(sim, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce2f7b",
   "metadata": {},
   "source": [
    "## 8. Pretrain SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "548c479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_simclr_loaders(batch_size=128, num_workers=0):\n",
    "    files = sorted(os.listdir(NPZ_DIR))\n",
    "    train_files = files[TRAIN_FILES]\n",
    "    base_ds = NPZFrameDataset(NPZ_DIR, train_files, transform=None)\n",
    "    aug = get_simclr_transform()\n",
    "    train_ds = SimCLRWrapper(base_ds, aug)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    return train_loader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def pretrain_simclr(epochs=50, batch_size=128, accum_steps=1, lr=3e-4,\n",
    "                    temperature=0.2, num_workers=0):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    train_loader = build_simclr_loaders(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    model = SimCLRModel(proj_out=128).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "\n",
    "    # New AMP API (removes deprecation warning)\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
    "\n",
    "    model.train()\n",
    "    os.makedirs(os.path.dirname(SIMCLR_SAVE), exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        pbar = tqdm(train_loader, desc=f\"[SimCLR] Epoch {epoch}/{epochs}\", leave=True)\n",
    "        running = 0.0\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        for step, (v1, v2) in enumerate(pbar, start=1):\n",
    "            v1, v2 = v1.to(device), v2.to(device)\n",
    "\n",
    "            # New autocast API; forward in AMP, loss computed stably in nt_xent_loss (fp32)\n",
    "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "                _, z1 = model(v1)\n",
    "                _, z2 = model(v2)\n",
    "\n",
    "            loss = nt_xent_loss(z1, z2, temperature=temperature) / max(1, accum_steps)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            if step % max(1,accum_steps) == 0:\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            running += loss.item() * max(1,accum_steps)\n",
    "            avg_loss = running / step\n",
    "            curr_lr = opt.param_groups[0]['lr']\n",
    "            pbar.set_postfix({'loss': f\"{avg_loss:.4f}\", 'lr': f\"{curr_lr:.2e}\"})\n",
    "\n",
    "        sched.step()\n",
    "        torch.save({'epoch': epoch, 'model': model.state_dict()}, SIMCLR_SAVE)\n",
    "        print(f\"Epoch {epoch}/{epochs} finished — avg loss {avg_loss:.4f}\")\n",
    "\n",
    "    print(f\"✅ SimCLR pretraining complete. Saved to: {SIMCLR_SAVE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb0342",
   "metadata": {},
   "source": [
    "### ⏯ Run pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54bbea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 1/50: 100%|██████████| 262/262 [02:20<00:00,  1.87it/s, loss=1.4281, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 finished — avg loss 1.4281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 2/50: 100%|██████████| 262/262 [02:21<00:00,  1.85it/s, loss=1.0477, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 finished — avg loss 1.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 3/50: 100%|██████████| 262/262 [02:18<00:00,  1.89it/s, loss=0.9838, lr=2.99e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 finished — avg loss 0.9838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 4/50: 100%|██████████| 262/262 [02:17<00:00,  1.91it/s, loss=0.9659, lr=2.97e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 finished — avg loss 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 5/50: 100%|██████████| 262/262 [02:23<00:00,  1.83it/s, loss=0.9407, lr=2.95e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 finished — avg loss 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 6/50: 100%|██████████| 262/262 [02:16<00:00,  1.92it/s, loss=0.9373, lr=2.93e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 finished — avg loss 0.9373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 7/50: 100%|██████████| 262/262 [02:20<00:00,  1.86it/s, loss=0.9525, lr=2.89e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 finished — avg loss 0.9525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 8/50: 100%|██████████| 262/262 [02:26<00:00,  1.79it/s, loss=0.9278, lr=2.86e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 finished — avg loss 0.9278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 9/50: 100%|██████████| 262/262 [02:26<00:00,  1.79it/s, loss=0.9116, lr=2.81e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 finished — avg loss 0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 10/50: 100%|██████████| 262/262 [02:20<00:00,  1.87it/s, loss=0.9094, lr=2.77e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 finished — avg loss 0.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 11/50: 100%|██████████| 262/262 [02:21<00:00,  1.85it/s, loss=0.9007, lr=2.71e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 finished — avg loss 0.9007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 12/50: 100%|██████████| 262/262 [02:27<00:00,  1.78it/s, loss=0.8961, lr=2.66e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 finished — avg loss 0.8961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 13/50: 100%|██████████| 262/262 [02:24<00:00,  1.81it/s, loss=0.8913, lr=2.59e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 finished — avg loss 0.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 14/50: 100%|██████████| 262/262 [02:20<00:00,  1.87it/s, loss=0.8905, lr=2.53e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 finished — avg loss 0.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 15/50: 100%|██████████| 262/262 [02:22<00:00,  1.84it/s, loss=0.8832, lr=2.46e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 finished — avg loss 0.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 16/50: 100%|██████████| 262/262 [02:28<00:00,  1.76it/s, loss=0.8817, lr=2.38e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 finished — avg loss 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 17/50: 100%|██████████| 262/262 [02:25<00:00,  1.80it/s, loss=0.8829, lr=2.30e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 finished — avg loss 0.8829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 18/50: 100%|██████████| 262/262 [02:20<00:00,  1.87it/s, loss=0.8808, lr=2.22e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 finished — avg loss 0.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 19/50: 100%|██████████| 262/262 [02:29<00:00,  1.76it/s, loss=0.8788, lr=2.14e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 finished — avg loss 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 20/50: 100%|██████████| 262/262 [02:30<00:00,  1.74it/s, loss=0.8756, lr=2.05e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 finished — avg loss 0.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 21/50: 100%|██████████| 262/262 [02:27<00:00,  1.78it/s, loss=0.8814, lr=1.96e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 finished — avg loss 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 22/50: 100%|██████████| 262/262 [02:33<00:00,  1.70it/s, loss=0.8772, lr=1.87e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 finished — avg loss 0.8772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 23/50: 100%|██████████| 262/262 [02:27<00:00,  1.77it/s, loss=0.8758, lr=1.78e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 finished — avg loss 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 24/50: 100%|██████████| 262/262 [02:34<00:00,  1.70it/s, loss=0.8727, lr=1.69e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 finished — avg loss 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 25/50: 100%|██████████| 262/262 [02:24<00:00,  1.82it/s, loss=0.8668, lr=1.59e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 finished — avg loss 0.8668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 26/50: 100%|██████████| 262/262 [02:21<00:00,  1.85it/s, loss=0.8677, lr=1.50e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 finished — avg loss 0.8677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 27/50: 100%|██████████| 262/262 [02:30<00:00,  1.74it/s, loss=0.8673, lr=1.41e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 finished — avg loss 0.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 28/50: 100%|██████████| 262/262 [02:31<00:00,  1.73it/s, loss=0.8639, lr=1.31e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 finished — avg loss 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 29/50: 100%|██████████| 262/262 [02:30<00:00,  1.75it/s, loss=0.8636, lr=1.22e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 finished — avg loss 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 30/50: 100%|██████████| 262/262 [02:33<00:00,  1.71it/s, loss=0.8602, lr=1.13e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 finished — avg loss 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 31/50: 100%|██████████| 262/262 [02:31<00:00,  1.72it/s, loss=0.8582, lr=1.04e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 finished — avg loss 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 32/50: 100%|██████████| 262/262 [02:32<00:00,  1.72it/s, loss=0.8584, lr=9.48e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 finished — avg loss 0.8584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 33/50: 100%|██████████| 262/262 [02:32<00:00,  1.72it/s, loss=0.8575, lr=8.61e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 finished — avg loss 0.8575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 34/50: 100%|██████████| 262/262 [02:33<00:00,  1.71it/s, loss=0.8543, lr=7.77e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 finished — avg loss 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 35/50: 100%|██████████| 262/262 [02:32<00:00,  1.72it/s, loss=0.8553, lr=6.96e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 finished — avg loss 0.8553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 36/50: 100%|██████████| 262/262 [02:29<00:00,  1.75it/s, loss=0.8580, lr=6.18e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 finished — avg loss 0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 37/50: 100%|██████████| 262/262 [02:30<00:00,  1.75it/s, loss=0.8528, lr=5.44e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 finished — avg loss 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 38/50: 100%|██████████| 262/262 [02:22<00:00,  1.84it/s, loss=0.8522, lr=4.73e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 finished — avg loss 0.8522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 39/50: 100%|██████████| 262/262 [02:26<00:00,  1.79it/s, loss=0.8517, lr=4.07e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 finished — avg loss 0.8517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 40/50: 100%|██████████| 262/262 [02:31<00:00,  1.73it/s, loss=0.8501, lr=3.44e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 finished — avg loss 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 41/50: 100%|██████████| 262/262 [02:29<00:00,  1.76it/s, loss=0.8510, lr=2.86e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 finished — avg loss 0.8510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 42/50: 100%|██████████| 262/262 [02:32<00:00,  1.72it/s, loss=0.8468, lr=2.34e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 finished — avg loss 0.8468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 43/50: 100%|██████████| 262/262 [02:31<00:00,  1.73it/s, loss=0.8491, lr=1.86e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 finished — avg loss 0.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 44/50: 100%|██████████| 262/262 [02:33<00:00,  1.71it/s, loss=0.8477, lr=1.43e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 finished — avg loss 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 45/50: 100%|██████████| 262/262 [02:30<00:00,  1.74it/s, loss=0.8449, lr=1.05e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 finished — avg loss 0.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 46/50: 100%|██████████| 262/262 [02:33<00:00,  1.71it/s, loss=0.8474, lr=7.34e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 finished — avg loss 0.8474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 47/50: 100%|██████████| 262/262 [02:33<00:00,  1.71it/s, loss=0.8448, lr=4.71e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 finished — avg loss 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 48/50: 100%|██████████| 262/262 [02:30<00:00,  1.74it/s, loss=0.8454, lr=2.66e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 finished — avg loss 0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 49/50: 100%|██████████| 262/262 [02:32<00:00,  1.72it/s, loss=0.8455, lr=1.18e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 finished — avg loss 0.8455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimCLR] Epoch 50/50: 100%|██████████| 262/262 [02:33<00:00,  1.71it/s, loss=0.8463, lr=2.96e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 finished — avg loss 0.8463\n",
      "✅ SimCLR pretraining complete. Saved to: D:/acouslic-ai-cse4622/saved_weights/simclr_resnet50_ultrasound.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: reduce epochs/batch if memory-limited\n",
    "pretrain_simclr(epochs=50, batch_size=64, accum_steps=2, lr=3e-4, temperature=0.2, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb2917f",
   "metadata": {},
   "source": [
    "## 9. Fine-tune the Frame Classifier (2-class CE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc70a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supervised augmentations (lighter than SSL)\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.95, 1.05)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=10),\n",
    "    T.RandomApply([T.GaussianBlur(3)], p=0.15),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "class FrameClassifier(nn.Module):\n",
    "    def __init__(self, simclr_ckpt_path=None, num_classes=2):\n",
    "        super().__init__()\n",
    "        # reuse SimCLR encoder definition\n",
    "        enc = _resnet50_imagenet_grayscale()\n",
    "        self.encoder = nn.Sequential(*list(enc.children())[:-1])  # [B,2048,1,1]\n",
    "        if simclr_ckpt_path and os.path.isfile(simclr_ckpt_path):\n",
    "            ckpt = torch.load(simclr_ckpt_path, map_location='cpu')\n",
    "            # load encoder params (ignore projector)\n",
    "            simclr_state = ckpt.get('model', ckpt)\n",
    "            # Extract keys that belong to encoder.*\n",
    "            encoder_state = {k.replace('encoder.', ''): v for k, v in simclr_state.items() if k.startswith('encoder.')}\n",
    "            self.encoder.load_state_dict(encoder_state, strict=False)\n",
    "            print(f\"Loaded SimCLR encoder weights from {simclr_ckpt_path}\")\n",
    "        self.head = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x).flatten(1)  # [B,2048]\n",
    "        return self.head(h)\n",
    "\n",
    "def build_cls_loaders(batch_size=16, num_workers=0):\n",
    "    files = sorted(os.listdir(NPZ_DIR))\n",
    "    train_files = files[TRAIN_FILES]\n",
    "    val_files = files[VAL_FILES]\n",
    "    train_ds = NPZFrameDataset(NPZ_DIR, train_files, transform=train_transform)\n",
    "    val_ds   = NPZFrameDataset(NPZ_DIR, val_files,   transform=val_transform)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def finetune_classifier(epochs=20, batch_size=16, lr=1e-4, weight_decay=1e-4, num_workers=0, patience=5):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    train_loader, val_loader = build_cls_loaders(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    model = FrameClassifier(simclr_ckpt_path=SIMCLR_SAVE, num_classes=2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "    best_acc, no_improve = 0.0, 0\n",
    "    os.makedirs(os.path.dirname(CLS_SAVE), exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader, desc=f\"[CLS] Epoch {epoch}/{epochs}\")\n",
    "        running = 0.0\n",
    "        for imgs, labels in pbar:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits = model(imgs)\n",
    "                loss = criterion(logits, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "            running += loss.item()\n",
    "            pbar.set_postfix(loss=running/max(1,len(pbar)))\n",
    "\n",
    "        # ---- Val ----\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                logits = model(imgs)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_acc = 100.0 * correct / max(1,total)\n",
    "        print(f\"Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        sched.step()\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc, no_improve = val_acc, 0\n",
    "            torch.save(model.state_dict(), CLS_SAVE)\n",
    "            print(f\"✅ Saved best model @ {best_acc:.2f}% → {CLS_SAVE}\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(\"⏹️ Early stopping.\")\n",
    "                break\n",
    "\n",
    "    print(f\"Done. Best Val Acc = {best_acc:.2f}%  → {CLS_SAVE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e0a37",
   "metadata": {},
   "source": [
    "### ⏯ Run fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a19f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11476\\3854392091.py:51: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SimCLR encoder weights from D:/acouslic-ai-cse4622/saved_weights/simclr_resnet50_ultrasound.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 1/20:   0%|          | 0/1050 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11476\\3854392091.py:64: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "[CLS] Epoch 1/20: 100%|██████████| 1050/1050 [01:36<00:00, 10.83it/s, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 92.42%\n",
      "✅ Saved best model @ 92.42% → D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 2/20: 100%|██████████| 1050/1050 [01:37<00:00, 10.71it/s, loss=0.171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 92.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 3/20: 100%|██████████| 1050/1050 [01:43<00:00, 10.15it/s, loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 93.61%\n",
      "✅ Saved best model @ 93.61% → D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 4/20: 100%|██████████| 1050/1050 [01:39<00:00, 10.52it/s, loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 92.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 5/20: 100%|██████████| 1050/1050 [01:39<00:00, 10.58it/s, loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 93.69%\n",
      "✅ Saved best model @ 93.69% → D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 6/20: 100%|██████████| 1050/1050 [01:39<00:00, 10.60it/s, loss=0.0934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 94.19%\n",
      "✅ Saved best model @ 94.19% → D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 7/20: 100%|██████████| 1050/1050 [01:41<00:00, 10.35it/s, loss=0.0837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 93.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 8/20: 100%|██████████| 1050/1050 [01:43<00:00, 10.19it/s, loss=0.0674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 93.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 9/20: 100%|██████████| 1050/1050 [01:41<00:00, 10.38it/s, loss=0.0649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 92.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 10/20: 100%|██████████| 1050/1050 [01:41<00:00, 10.35it/s, loss=0.0511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 92.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CLS] Epoch 11/20: 100%|██████████| 1050/1050 [01:43<00:00, 10.10it/s, loss=0.0421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 91.31%\n",
      "⏹️ Early stopping.\n",
      "Done. Best Val Acc = 94.19%  → D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finetune_classifier(epochs=20, batch_size=16, lr=1e-4, weight_decay=1e-4, num_workers=0, patience=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd19ff",
   "metadata": {},
   "source": [
    "## 10. Inference helper: pick best frame in a sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e28d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def pick_best_frame(npz_path, model_ckpt=CLS_SAVE, batch_size=64):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # Load classifier\n",
    "    clf = FrameClassifier(simclr_ckpt_path=None, num_classes=2).to(device)\n",
    "    clf.load_state_dict(torch.load(model_ckpt, map_location=device))\n",
    "    clf.eval()\n",
    "\n",
    "    # Deterministic preprocessing\n",
    "    def preprocess(batch):\n",
    "        batch = torch.from_numpy(batch.astype(np.float32))\n",
    "        # normalize [0,1]\n",
    "        mn, mx = batch.min(), batch.max()\n",
    "        batch = (batch - mn) / (mx - mn + 1e-8)\n",
    "        batch = batch.unsqueeze(1)  # B×1×H×W\n",
    "        batch = F.interpolate(batch, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        batch = (batch - 0.5) / 0.5\n",
    "        return batch\n",
    "\n",
    "    case = np.load(npz_path, mmap_mode='r')\n",
    "    images = case['image']  # (F,H,W)\n",
    "\n",
    "    best_idx, best_score = None, -1.0\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, len(images), batch_size):\n",
    "            chunk = images[start:start+batch_size]\n",
    "            x = preprocess(chunk).to(device)\n",
    "            logits = clf(x)\n",
    "            probs = torch.softmax(logits, dim=1)[:,1]  # P(abdomen)\n",
    "            s, j = torch.max(probs, dim=0)\n",
    "            s, j = s.item(), j.item()\n",
    "            if s > best_score:\n",
    "                best_score = s\n",
    "                best_idx = start + j\n",
    "    return best_idx, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d1a0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best frame: 20 score: 0.9978273510932922\n"
     ]
    }
   ],
   "source": [
    "npz_path = os.path.join(NPZ_DIR, sorted(os.listdir(NPZ_DIR))[210])\n",
    "idx, score = pick_best_frame(npz_path)\n",
    "print('Best frame:', idx, 'score:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857155c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating files [255:299] → 45 cases\n",
      "\n",
      "d42fb920-5df1-4341-93df-480c17355e44.npz\n",
      "  Frames: 840 | Pred idx:   68 (p=0.9934)\n",
      "  GT positives: [799, 800, 801, 802, 803, 804, 805, 806]\n",
      "  Nearest GT: 799 | |dist|=731 | Hit any +ve? NO\n",
      "\n",
      "d5471cfd-6090-4d42-9a95-67ccbfbf612e.npz\n",
      "  Frames: 840 | Pred idx:   44 (p=0.9971)\n",
      "  GT positives: [42, 43, 44, 45, 46, 47, 48, 176, 177, 178, 179, 180] ...\n",
      "  Nearest GT: 44 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "d571d4e1-ff80-44b9-a481-07961c6a1208.npz\n",
      "  Frames: 840 | Pred idx:   45 (p=0.9955)\n",
      "  GT positives: [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54] ...\n",
      "  Nearest GT: 45 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "d5c3cfee-53ac-4021-8c1b-098c189f630e.npz\n",
      "  Frames: 840 | Pred idx:  626 (p=0.9988)\n",
      "  GT positives: [20, 21, 22, 23, 24, 25, 164, 165, 166, 167, 168, 169] ...\n",
      "  Nearest GT: 626 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "d5f8c859-de93-4a50-b324-1ae4ad0267d4.npz\n",
      "  Frames: 840 | Pred idx:   69 (p=0.9997)\n",
      "  GT positives: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75] ...\n",
      "  Nearest GT: 69 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "d624338f-d09b-4bda-bbc3-3fa417015d6b.npz\n",
      "  Frames: 840 | Pred idx:   75 (p=0.9981)\n",
      "  GT positives: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75] ...\n",
      "  Nearest GT: 75 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "d77b6ece-da17-4f88-818c-0c7340b3e54f.npz\n",
      "  Frames: 840 | Pred idx:   58 (p=0.9998)\n",
      "  GT positives: [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 217, 218] ...\n",
      "  Nearest GT: 58 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "d812091a-3635-4d51-9290-6adb3aa8681e.npz\n",
      "  Frames: 840 | Pred idx:   36 (p=0.9926)\n",
      "  GT positives: [34, 35, 36, 37, 38, 39, 179, 180, 181, 182, 183]\n",
      "  Nearest GT: 36 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "d8c3665a-4dc3-40ce-b716-f30aab365332.npz\n",
      "  Frames: 840 | Pred idx:  639 (p=0.9749)\n",
      "  GT positives: [591, 592, 593, 594, 595, 596, 597]\n",
      "  Nearest GT: 597 | |dist|=42 | Hit any +ve? NO\n",
      "\n",
      "db9d468d-cb20-4d5e-b059-31728f5950e6.npz\n",
      "  Frames: 840 | Pred idx:  330 (p=0.9998)\n",
      "  GT positives: [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51] ...\n",
      "  Nearest GT: 331 | |dist|=1 | Hit any +ve? NO\n",
      "\n",
      "dc0cbbdf-e4bb-4de5-958a-10576129e440.npz\n",
      "  Frames: 840 | Pred idx:   47 (p=0.9992)\n",
      "  GT positives: [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53] ...\n",
      "  Nearest GT: 47 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "dc381d50-124d-4bc8-b504-9c9c3a3ae697.npz\n",
      "  Frames: 840 | Pred idx:   45 (p=0.9998)\n",
      "  GT positives: [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54] ...\n",
      "  Nearest GT: 45 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "dcdcb9a4-fec7-45a2-b2b7-a282f963c551.npz\n",
      "  Frames: 840 | Pred idx:   59 (p=0.9981)\n",
      "  GT positives: [54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
      "  Nearest GT: 59 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "de35b365-6308-4974-b2fc-976e26584810.npz\n",
      "  Frames: 840 | Pred idx:  651 (p=0.9848)\n",
      "  GT positives: [650, 651, 652, 653]\n",
      "  Nearest GT: 651 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "de45de1a-2482-4024-ac8b-c18c4834b379.npz\n",
      "  Frames: 840 | Pred idx:  633 (p=0.9932)\n",
      "  GT positives: [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "  Nearest GT: 56 | |dist|=577 | Hit any +ve? NO\n",
      "\n",
      "de93dac8-41e0-4b03-946e-0accda6010af.npz\n",
      "  Frames: 840 | Pred idx:   35 (p=0.9983)\n",
      "  GT positives: [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42] ...\n",
      "  Nearest GT: 35 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "de964751-ec9d-4c53-9da3-9d7f200987b1.npz\n",
      "  Frames: 840 | Pred idx:   38 (p=0.9993)\n",
      "  GT positives: [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] ...\n",
      "  Nearest GT: 38 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "decd2d84-79a2-4239-b802-5afdf318e7e6.npz\n",
      "  Frames: 840 | Pred idx:   42 (p=0.9913)\n",
      "  GT positives: [43, 44, 45, 46, 47, 172, 173, 174, 175, 176, 177, 178] ...\n",
      "  Nearest GT: 43 | |dist|=1 | Hit any +ve? NO\n",
      "\n",
      "e3670fa9-574c-4fbc-89af-f69aad63696d.npz\n",
      "  Frames: 840 | Pred idx:  315 (p=0.9999)\n",
      "  GT positives: [45, 46, 49, 50, 51, 52, 53, 312, 313, 314, 315, 316] ...\n",
      "  Nearest GT: 315 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "e5053a72-46f6-496d-8252-c8b531b5039b.npz\n",
      "  Frames: 840 | Pred idx:  604 (p=0.9878)\n",
      "  GT positives: [43, 44, 45, 46, 603, 604, 605]\n",
      "  Nearest GT: 604 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "e5a2d914-a35c-4207-9bc8-5e5cee7dbfba.npz\n",
      "  Frames: 840 | Pred idx:  469 (p=0.9966)\n",
      "  GT positives: [158, 159, 160, 161, 162, 163, 164, 285, 286, 287, 288, 289] ...\n",
      "  Nearest GT: 470 | |dist|=1 | Hit any +ve? NO\n",
      "\n",
      "e608e364-6898-442c-be0f-aea8d7735c15.npz\n",
      "  Frames: 840 | Pred idx:   55 (p=0.9995)\n",
      "  GT positives: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
      "  Nearest GT: 55 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "e9025780-a9bb-4300-be4e-fb220e824646.npz\n",
      "  Frames: 840 | Pred idx:   72 (p=0.9999)\n",
      "  GT positives: [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 198] ...\n",
      "  Nearest GT: 72 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "e9043ff5-f8a4-4095-bc44-26232e1be011.npz\n",
      "  Frames: 840 | Pred idx:   15 (p=0.9977)\n",
      "  GT positives: [13, 14, 15, 16, 17, 18, 140, 141, 142]\n",
      "  Nearest GT: 15 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "ea2a8fbf-f7fe-43f4-9e0d-1da0ae9b1a0c.npz\n",
      "  Frames: 840 | Pred idx:   30 (p=0.9951)\n",
      "  GT positives: [30, 31, 32, 33, 34, 35, 150, 151, 152, 153, 154, 155] ...\n",
      "  Nearest GT: 30 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "ea724ff0-9990-4557-ab53-16f2fe1f1c8f.npz\n",
      "  Frames: 840 | Pred idx:   56 (p=0.9932)\n",
      "  GT positives: [51, 52, 53, 54, 55, 56, 57, 180, 181, 182, 183, 184] ...\n",
      "  Nearest GT: 56 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "ea86047a-bae4-464b-a2ed-015935bebb2a.npz\n",
      "  Frames: 840 | Pred idx:   66 (p=0.9984)\n",
      "  GT positives: [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61] ...\n",
      "  Nearest GT: 66 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "ebadcfcb-a682-4493-8502-2adc194bba8c.npz\n",
      "  Frames: 840 | Pred idx:  467 (p=0.9987)\n",
      "  GT positives: [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151] ...\n",
      "  Nearest GT: 467 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "ec65aa35-d54c-44da-80a4-883f631c345e.npz\n",
      "  Frames: 840 | Pred idx:  606 (p=0.9795)\n",
      "  GT positives: [32, 33]\n",
      "  Nearest GT: 33 | |dist|=573 | Hit any +ve? NO\n",
      "\n",
      "ee2e6220-b2f3-4c8e-9c85-f04ed0a6b6f7.npz\n",
      "  Frames: 840 | Pred idx:  495 (p=0.9989)\n",
      "  GT positives: [296, 297, 298, 299, 300, 301, 302, 481, 482, 483, 484, 485] ...\n",
      "  Nearest GT: 495 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "eee8da44-8db7-4c9e-b52d-b6d461158a4e.npz\n",
      "  Frames: 840 | Pred idx:  627 (p=0.9996)\n",
      "  GT positives: [606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617] ...\n",
      "  Nearest GT: 627 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f1fcabfc-f998-44c7-8420-c7a5ae5aaab7.npz\n",
      "  Frames: 840 | Pred idx:   55 (p=0.9254)\n",
      "  GT positives: [55]\n",
      "  Nearest GT: 55 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f256d725-9b06-4a88-a6b5-f9eee0f050f4.npz\n",
      "  Frames: 840 | Pred idx:   46 (p=0.9982)\n",
      "  GT positives: [41, 42, 43, 44, 45, 46, 47, 48, 49, 180, 181, 182] ...\n",
      "  Nearest GT: 46 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f4488c3c-556e-43bd-95f9-ae4cbb7c7093.npz\n",
      "  Frames: 840 | Pred idx:   66 (p=0.9969)\n",
      "  GT positives: [510, 511, 512, 513, 514]\n",
      "  Nearest GT: 510 | |dist|=444 | Hit any +ve? NO\n",
      "\n",
      "f4bebd1e-d3ca-4186-902a-2b6ef9391060.npz\n",
      "  Frames: 840 | Pred idx:   40 (p=0.9935)\n",
      "  GT positives: [38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49] ...\n",
      "  Nearest GT: 40 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f5611c30-d04b-4691-9bd6-1e6de392a63c.npz\n",
      "  Frames: 840 | Pred idx:   70 (p=0.9851)\n",
      "  GT positives: [65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 219, 220] ...\n",
      "  Nearest GT: 70 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f5a702f0-d759-4b53-8215-462e8145e638.npz\n",
      "  Frames: 840 | Pred idx:  169 (p=0.9867)\n",
      "  GT positives: [30, 31, 32, 33, 34, 164, 165, 166, 167, 168, 169, 170] ...\n",
      "  Nearest GT: 169 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f5e853b1-9465-40b0-a246-7d3f6cb94de7.npz\n",
      "  Frames: 840 | Pred idx:  475 (p=0.9969)\n",
      "  GT positives: [4, 5, 6, 7, 8, 9, 10, 44, 45, 46, 47, 157] ...\n",
      "  Nearest GT: 475 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f5e97e20-ad47-46e4-bf35-3f0c01ff51d0.npz\n",
      "  Frames: 840 | Pred idx:   86 (p=0.9953)\n",
      "  GT positives: [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91]\n",
      "  Nearest GT: 86 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f8039e25-4652-440c-9476-b425f3fccb22.npz\n",
      "  Frames: 840 | Pred idx:   54 (p=0.9956)\n",
      "  GT positives: [52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] ...\n",
      "  Nearest GT: 54 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "f9ba7ffd-bc66-4da6-b97d-1286d760a184.npz\n",
      "  Frames: 840 | Pred idx:   55 (p=0.9999)\n",
      "  GT positives: [55, 56, 57, 58, 59, 324, 325, 326, 327, 328, 329, 330] ...\n",
      "  Nearest GT: 55 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "fc167d1b-045a-4057-936d-4862644af1f3.npz\n",
      "  Frames: 840 | Pred idx:   88 (p=0.9982)\n",
      "  GT positives: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91] ...\n",
      "  Nearest GT: 88 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "fc63df40-f6ca-4917-99ba-dbe4310a6d04.npz\n",
      "  Frames: 840 | Pred idx:  617 (p=0.9984)\n",
      "  GT positives: [605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616] ...\n",
      "  Nearest GT: 617 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "fdfd752d-2d83-4452-a3ba-97a626676334.npz\n",
      "  Frames: 840 | Pred idx:  228 (p=0.9956)\n",
      "  GT positives: [31, 32, 33, 34, 35, 36, 224, 225, 226, 227, 228, 229] ...\n",
      "  Nearest GT: 228 | |dist|=0 | Hit any +ve? YES\n",
      "\n",
      "fe236600-a41c-4d26-b4ea-6d3ff109cf41.npz\n",
      "  Frames: 840 | Pred idx:  141 (p=0.9943)\n",
      "  GT positives: [282, 283, 284, 285, 286, 287, 288, 289, 290, 291]\n",
      "  Nearest GT: 282 | |dist|=141 | Hit any +ve? NO\n",
      "\n",
      "====== Summary (255–299) ======\n",
      "Files evaluated:      45\n",
      "Mean |dist to nearest +ve|: 55.80 frames\n",
      "Hit any positive:     36/45  (80.0%)\n",
      "Exact first-positive: 3/45  (6.7%)\n",
      "Mean predicted prob:  0.9937\n",
      "Saved per-case CSV to: d:\\acouslic-ai-cse4622\\notebooks\\range_255_300_results.csv\n",
      "{'n_evaluated': 45.0, 'mae_to_nearest_positive': 55.8, 'acc_any_positive': 0.8, 'acc_exact_first_positive': 0.06666666666666667, 'mean_pred_prob': 0.9937456263436212, 'csv_path': 'd:\\\\acouslic-ai-cse4622\\\\notebooks\\\\range_255_300_results.csv'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def _load_model(ckpt_path: str, num_classes: int = 2) -> Tuple[torch.nn.Module, str]:\n",
    "    \"\"\"\n",
    "    Load the frame classifier and return (model, device).\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = FrameClassifier(num_classes=num_classes).to(device)\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "\n",
    "def _get_label_array(case_npz: np.lib.npyio.NpzFile) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract a 1D (F,) label array from common keys.\n",
    "    Raises KeyError if none are found.\n",
    "    \"\"\"\n",
    "    for key in (\"label\", \"labels\", \"y\", \"gt\", \"target\"):\n",
    "        if key in case_npz:\n",
    "            return np.asarray(case_npz[key]).reshape(-1)\n",
    "    raise KeyError(\"No per-frame label key found (tried: label, labels, y, gt, target).\")\n",
    "\n",
    "\n",
    "def _predict_best_frame(npz_path: str, model: torch.nn.Module, device: str, batch_size: int = 64) -> Tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Run inference over all frames in an NPZ and return (best_frame_index, best_score).\n",
    "    Assumes NPZ has key 'image' shaped (F, H, W).\n",
    "    \"\"\"\n",
    "    case = np.load(npz_path, mmap_mode=\"r\")\n",
    "    images = case[\"image\"]  # (F, H, W)\n",
    "\n",
    "    best_idx, best_score = None, -1.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, len(images), batch_size):\n",
    "            batch = images[start:start + batch_size].astype(np.float32)     # (B,H,W)\n",
    "            b = torch.from_numpy(batch).unsqueeze(1)                        # (B,1,H,W)\n",
    "\n",
    "            # Per-frame min-max normalization to [0,1]\n",
    "            b_min = b.amin(dim=(2, 3), keepdim=True)\n",
    "            b_max = b.amax(dim=(2, 3), keepdim=True)\n",
    "            b = (b - b_min) / (b_max - b_min + 1e-8)\n",
    "\n",
    "            # Resize and normalize to [-1, 1]\n",
    "            b = F.interpolate(b, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "            b = (b - 0.5) / 0.5\n",
    "            b = b.to(device)\n",
    "\n",
    "            logits = model(b)\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]                      # P(positive class)\n",
    "\n",
    "            max_prob, max_idx = torch.max(probs, dim=0)\n",
    "            if max_prob.item() > best_score:\n",
    "                best_score = max_prob.item()\n",
    "                best_idx = start + max_idx.item()\n",
    "\n",
    "    return int(best_idx), float(best_score)\n",
    "\n",
    "\n",
    "def evaluate_fixed_range(\n",
    "    root_dir: str,\n",
    "    ckpt_path: str,\n",
    "    start_idx: int = 255,\n",
    "    end_idx: int = 300,\n",
    "    batch_size: int = 64,\n",
    "    positive_values: Tuple[int, ...] = (1, 2),\n",
    "    save_csv: str = \"range_255_300_results.csv\",\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate files in sorted(os.listdir(root_dir))[start_idx : end_idx+1].\n",
    "\n",
    "    For each case:\n",
    "      - Predict best frame with the classifier.\n",
    "      - Extract ground-truth positives from per-frame labels inside the NPZ.\n",
    "      - Compute distance to the nearest positive (0 = exact hit).\n",
    "      - Record metrics and save per-case rows to CSV.\n",
    "\n",
    "    Returns a dict with aggregate metrics and the CSV path.\n",
    "    \"\"\"\n",
    "    # Load model once\n",
    "    model, device = _load_model(ckpt_path)\n",
    "\n",
    "    # Collect files\n",
    "    files = sorted([f for f in os.listdir(root_dir) if f.lower().endswith(\".npz\")])\n",
    "    if end_idx >= len(files):\n",
    "        raise IndexError(f\"end_idx={end_idx} out of range for {len(files)} files in {root_dir}\")\n",
    "    target_files = files[start_idx:end_idx + 1]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Evaluating files [{start_idx}:{end_idx}] → {len(target_files)} cases\\n\")\n",
    "\n",
    "    rows: List[Dict[str, object]] = []\n",
    "    total = 0\n",
    "    hits_anypos = 0\n",
    "    exact_firstpos_hits = 0\n",
    "    prob_values: List[float] = []\n",
    "    dists: List[int] = []\n",
    "\n",
    "    for fname in target_files:\n",
    "        path = os.path.join(root_dir, fname)\n",
    "        case = np.load(path, mmap_mode=\"r\")\n",
    "\n",
    "        # Load labels\n",
    "        try:\n",
    "            labels = _get_label_array(case)  # (F,)\n",
    "        except KeyError:\n",
    "            if verbose:\n",
    "                print(f\"[WARN] {fname}: missing labels → skipped.\")\n",
    "            rows.append({\n",
    "                \"filename\": fname, \"n_frames\": int(case[\"image\"].shape[0]),\n",
    "                \"pred_idx\": \"\", \"pred_prob\": \"\", \"gt_positives\": \"\",\n",
    "                \"nearest_gt\": \"\", \"abs_dist\": \"\", \"hit_anypos\": \"\", \"exact_firstpos\": \"\",\n",
    "                \"note\": \"No per-frame labels found\",\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        positives = np.where(np.isin(labels, positive_values))[0]  # indices of positive frames\n",
    "\n",
    "        # Predict\n",
    "        pred_idx, pred_prob = _predict_best_frame(path, model=model, device=device, batch_size=batch_size)\n",
    "\n",
    "        total += 1\n",
    "        prob_values.append(pred_prob)\n",
    "\n",
    "        # Distance to nearest positive\n",
    "        if positives.size > 0:\n",
    "            nearest_gt = int(positives[np.argmin(np.abs(positives - pred_idx))])\n",
    "            dist = int(abs(nearest_gt - pred_idx))\n",
    "        else:\n",
    "            nearest_gt = None\n",
    "            dist = 0  # defined as 0 when no positives exist\n",
    "\n",
    "        dists.append(dist)\n",
    "\n",
    "        # Any positive hit?\n",
    "        anypos = (pred_idx in positives) if positives.size > 0 else True  # no positives → trivially \"not a miss\"\n",
    "        hits_anypos += int(anypos)\n",
    "\n",
    "        # Exact match to first positive (argmax proxy)\n",
    "        if positives.size > 0:\n",
    "            first_pos = int(positives[0])\n",
    "        else:\n",
    "            first_pos = int(np.argmax(labels))  # fallback if all zeros\n",
    "        exact_firstpos_hits += int(pred_idx == first_pos)\n",
    "\n",
    "        # Row\n",
    "        rows.append({\n",
    "            \"filename\": fname,\n",
    "            \"n_frames\": int(labels.shape[0]),\n",
    "            \"pred_idx\": int(pred_idx),\n",
    "            \"pred_prob\": round(float(pred_prob), 6),\n",
    "            \"gt_positives\": \";\".join(map(str, positives.tolist())) if positives.size > 0 else \"\",\n",
    "            \"nearest_gt\": \"\" if nearest_gt is None else int(nearest_gt),\n",
    "            \"abs_dist\": int(dist),\n",
    "            \"hit_anypos\": int(anypos),\n",
    "            \"exact_firstpos\": int(pred_idx == first_pos),\n",
    "            \"note\": \"\",\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{fname}\")\n",
    "            print(f\"  Frames: {len(labels)} | Pred idx: {pred_idx:4d} (p={pred_prob:.4f})\")\n",
    "            if positives.size > 0:\n",
    "                plist = positives.tolist()\n",
    "                print(f\"  GT positives: {plist[:12]}{' ...' if len(plist) > 12 else ''}\")\n",
    "                print(f\"  Nearest GT: {nearest_gt} | |dist|={dist} | Hit any +ve? {'YES' if anypos else 'NO'}\\n\")\n",
    "            else:\n",
    "                print(\"  GT positives: [] (no positive frames) | |dist|=0 (defined)\\n\")\n",
    "\n",
    "    # Aggregates\n",
    "    if total > 0:\n",
    "        mae = float(np.mean(dists))\n",
    "        acc_anypos = hits_anypos / total\n",
    "        acc_exact_first = exact_firstpos_hits / total\n",
    "        mean_prob = float(np.mean(prob_values))\n",
    "    else:\n",
    "        mae = math.nan\n",
    "        acc_anypos = math.nan\n",
    "        acc_exact_first = math.nan\n",
    "        mean_prob = math.nan\n",
    "\n",
    "    # Save CSV\n",
    "    fieldnames = [\n",
    "        \"filename\", \"n_frames\", \"pred_idx\", \"pred_prob\", \"gt_positives\",\n",
    "        \"nearest_gt\", \"abs_dist\", \"hit_anypos\", \"exact_firstpos\", \"note\",\n",
    "    ]\n",
    "    with open(save_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"====== Summary ({}–{}) ======\".format(start_idx, end_idx))\n",
    "        print(f\"Files evaluated:      {total}\")\n",
    "        print(f\"Mean |dist to nearest +ve|: {mae:.2f} frames\" if not math.isnan(mae) else \"MAE: N/A\")\n",
    "        print(f\"Hit any positive:     {hits_anypos}/{total}  ({acc_anypos*100:.1f}%)\" if not math.isnan(acc_anypos) else \"Hit any +ve: N/A\")\n",
    "        print(f\"Exact first-positive: {exact_firstpos_hits}/{total}  ({acc_exact_first*100:.1f}%)\" if not math.isnan(acc_exact_first) else \"Exact first-positive: N/A\")\n",
    "        print(f\"Mean predicted prob:  {mean_prob:.4f}\" if not math.isnan(mean_prob) else \"Mean prob: N/A\")\n",
    "        print(f\"Saved per-case CSV to: {os.path.abspath(save_csv)}\")\n",
    "\n",
    "    return {\n",
    "        \"n_evaluated\": float(total),\n",
    "        \"mae_to_nearest_positive\": mae,\n",
    "        \"acc_any_positive\": acc_anypos,\n",
    "        \"acc_exact_first_positive\": acc_exact_first,\n",
    "        \"mean_pred_prob\": mean_prob,\n",
    "        \"csv_path\": os.path.abspath(save_csv),\n",
    "    }\n",
    "\n",
    "# ---------------- Example ----------------\n",
    "summary = evaluate_fixed_range(\n",
    "    root_dir=\"D:/dataset/mult_mha_to_npz\",\n",
    "    ckpt_path=\"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\",\n",
    "    start_idx=255,\n",
    "    end_idx=299,\n",
    "    batch_size=64,\n",
    "    positive_values=(1, 2),                     # adjust if your labels differ\n",
    "    save_csv=\"range_255_300_results.csv\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b46959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def confusion_binary_from_counts(tp, fp, fn, tn) -> np.ndarray:\n",
    "    return np.array([[tn, fp],\n",
    "                     [fn, tp]], dtype=int)\n",
    "    \n",
    "\n",
    "def evaluate_frame_level_confusion(\n",
    "    root_dir: str,\n",
    "    ckpt_path: str,\n",
    "    threshold: float = 0.5,\n",
    "    batch_size: int = 128,\n",
    "    positive_values: Tuple[int, ...] = (1, 2),\n",
    "    num_classes: int = 2,\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    #model, device = _load_model(ckpt_path, num_classes=num_classes)\n",
    "\n",
    "    files = sorted([f for f in os.listdir(root_dir) if f.lower().endswith(\".npz\")])\n",
    "    tp = fp = fn = tn = 0\n",
    "    n_frames_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for fname in files:\n",
    "            path = os.path.join(root_dir, fname)\n",
    "            case = np.load(path, mmap_mode=\"r\")\n",
    "\n",
    "            # Must have per-frame labels\n",
    "            try:\n",
    "                labels = _get_label_array(case)  # (F,)\n",
    "            except KeyError:\n",
    "                if verbose:\n",
    "                    print(f\"[WARN] {fname}: missing labels → skipped for confusion.\")\n",
    "                continue\n",
    "\n",
    "            images = case[\"image\"].astype(np.float32)  # (F,H,W)\n",
    "            F_count = images.shape[0]\n",
    "            n_frames_total += F_count\n",
    "\n",
    "            # Ground-truth (binary)\n",
    "            y_true = np.isin(labels, positive_values).astype(np.int64)  # (F,)\n",
    "\n",
    "            # Batched inference to get per-frame probs\n",
    "            probs_all = []\n",
    "            for start in range(0, F_count, batch_size):\n",
    "                batch = images[start:start + batch_size]                 # (B,H,W)\n",
    "                b = torch.from_numpy(batch).unsqueeze(1)                 # (B,1,H,W)\n",
    "\n",
    "                # Per-frame min-max to [0,1]\n",
    "                b_min = b.amin(dim=(2, 3), keepdim=True)\n",
    "                b_max = b.amax(dim=(2, 3), keepdim=True)\n",
    "                b = (b - b_min) / (b_max - b_min + 1e-8)\n",
    "\n",
    "                # Resize → [-1,1]\n",
    "                b = F.interpolate(b, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "                b = (b - 0.5) / 0.5\n",
    "                b = b.to(device)\n",
    "\n",
    "                logits = model(b)\n",
    "                probs = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()  # (B,)\n",
    "                probs_all.append(probs)\n",
    "\n",
    "            probs_all = np.concatenate(probs_all, axis=0)                # (F,)\n",
    "            y_pred = (probs_all >= threshold).astype(np.int64)\n",
    "\n",
    "            # Update counts\n",
    "            tp += int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "            fp += int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "            fn += int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "            tn += int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "\n",
    "    cm = confusion_binary_from_counts(tp, fp, fn, tn)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Frame-level confusion matrix (rows: true [0,1], cols: pred [0,1])\")\n",
    "        print(cm)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        acc  = (tp + tn) / max(1, (tp+tn+fp+fn))\n",
    "        print(f\"Frames evaluated: {n_frames_total}\")\n",
    "        print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f}\")\n",
    "\n",
    "    return {\"confusion_matrix\": cm, \"tp\": tp, \"fp\": fp, \"fn\": fn, \"tn\": tn}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42d2cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_frame_level_confusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/dataset/mult_mha_to_npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mevaluate_frame_level_confusion\u001b[1;34m(root_dir, ckpt_path, threshold, batch_size, positive_values, num_classes, verbose)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_frame_level_confusion\u001b[39m(\n\u001b[0;32m     12\u001b[0m     root_dir: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     13\u001b[0m     ckpt_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m]:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#model, device = _load_model(ckpt_path, num_classes=num_classes)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(root_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[0;32m     23\u001b[0m     tp \u001b[38;5;241m=\u001b[39m fp \u001b[38;5;241m=\u001b[39m fn \u001b[38;5;241m=\u001b[39m tn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     24\u001b[0m     n_frames_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_frame_level_confusion(\n",
    "    root_dir=\"D:/dataset/mult_mha_to_npz\",\n",
    "    ckpt_path=\"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_from_simclr.pth\",\n",
    "    threshold= 0.5,\n",
    "    batch_size=128,\n",
    "    positive_values=(1, 2),     \n",
    "    num_classes =2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d2d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
