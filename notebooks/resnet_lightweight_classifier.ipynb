{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52195172",
   "metadata": {},
   "source": [
    "### Setup & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd93e2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24953dbbf10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random, math, numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "try:\n",
    "    # torchvision v2 transforms (tensor-native)\n",
    "    from torchvision.transforms import v2 as T\n",
    "except:\n",
    "    # fallback to classic, but v2 is recommended\n",
    "    import torchvision.transforms as T\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----- Paths (edit these) -----\n",
    "TRAIN_DIR = \"D:/dataset/npz_80_tiny\"                   # reduced, balanced-ish for training\n",
    "VAL_DIR   = \"D:/dataset/converted_classifier_npz_compact\"  # full-length compacts for validation/inference\n",
    "SAVE_PATH = \"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_allinone.pth\"\n",
    "\n",
    "# ----- Splits (edit indices as you like) -----\n",
    "train_files = sorted([f for f in os.listdir(TRAIN_DIR) if f.endswith(\".npz\")])[:210]\n",
    "val_files   = sorted([f for f in os.listdir(VAL_DIR)   if f.endswith(\".npz\")])[210:255]\n",
    "\n",
    "# ----- Training hyperparams -----\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH  = 64\n",
    "EPOCHS     = 20\n",
    "PATIENCE   = 5\n",
    "LR_HEAD    = 1e-3     # warmup (head-only)\n",
    "LR_ALL     = 1e-4     # full fine-tune\n",
    "WEIGHT_DEC = 1e-4\n",
    "SEED       = 42\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc25190",
   "metadata": {},
   "source": [
    "\n",
    "### Utilities: aspect-preserving letterbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8087125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _letterbox_to_square(x: torch.Tensor, size: int = 224) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: (B,1,H,W) or (1,H,W) in [0,1] -> pad to square (keep aspect) -> resize to (..,1,size,size)\n",
    "    \"\"\"\n",
    "    is_batched = (x.dim() == 4)\n",
    "    if not is_batched:\n",
    "        x = x.unsqueeze(0)  # (1,1,H,W)\n",
    "    _, _, H, W = x.shape\n",
    "    s = max(H, W)\n",
    "    pad_h = (s - H) // 2\n",
    "    pad_w = (s - W) // 2\n",
    "    x = F.pad(x, (pad_w, s - W - pad_w, pad_h, s - H - pad_h))  # L,R,T,B\n",
    "    x = F.interpolate(x, size=(size, size), mode=\"bilinear\", align_corners=False)\n",
    "    return x if is_batched else x.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6543a3",
   "metadata": {},
   "source": [
    "### 2) Dataset with tensor transforms (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a063f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreloadedNPZFrameDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Preloads all frames from the given NPZ files into RAM as a single tensor.\n",
    "    binary=True merges class 2->1 (optimal+suboptimal).\n",
    "    resize_mode: 'letterbox' (preserves aspect) or 'squash' (direct resize).\n",
    "    dtype=torch.float16 to save RAM (use AMP on GPU).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 npz_dir: str,\n",
    "                 files: list[str],\n",
    "                 binary: bool = True,\n",
    "                 out_size: int = 224,\n",
    "                 resize_mode: str = \"letterbox\",\n",
    "                 dtype: torch.dtype = torch.float16):\n",
    "        self.binary = binary\n",
    "        self.out_size = out_size\n",
    "        self.resize_mode = resize_mode\n",
    "        self.dtype = dtype\n",
    "\n",
    "        imgs_all = []\n",
    "        labels_all = []\n",
    "\n",
    "        for f in files:\n",
    "            path = os.path.join(npz_dir, f)\n",
    "            case = np.load(path, allow_pickle=True)\n",
    "            imgs = case[\"image\"]                    # (T,H,W) uint8\n",
    "            y    = case[\"label\"].astype(np.int64)   # (T,)\n",
    "            if binary:\n",
    "                y[y == 2] = 1\n",
    "\n",
    "            t = torch.from_numpy(imgs).unsqueeze(1).float() / 255.0  # (T,1,H,W) [0,1]\n",
    "\n",
    "            if resize_mode == \"letterbox\":\n",
    "                # letterbox each frame (simple loop is reliable & clear)\n",
    "                out_frames = []\n",
    "                for fr in t:\n",
    "                    out_frames.append(_letterbox_to_square(fr, size=out_size))  # (1,S,S)\n",
    "                t = torch.stack(out_frames, dim=0)  # (T,1,S,S)\n",
    "            else:  # 'squash'\n",
    "                t = F.interpolate(t, size=(out_size, out_size), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            # normalize to [-1,1]\n",
    "            t = (t - 0.5) / 0.5\n",
    "            imgs_all.append(t.to(dtype=dtype).cpu())\n",
    "            labels_all.append(torch.from_numpy(y).long())\n",
    "\n",
    "        self.images = torch.cat(imgs_all, dim=0)   # (N,1,S,S) FP16 by default\n",
    "        self.labels = torch.cat(labels_all, dim=0) # (N,)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.numel()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af0fa1",
   "metadata": {},
   "source": [
    "### 3) Balanced batch sampler (≈50/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5ad6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Finite, per-epoch sampler: ~50/50 pos/neg in each batch.\n",
    "    Steps per epoch = ceil(len(pos) / (batch_size/2)).\n",
    "    \"\"\"\n",
    "    def __init__(self, labels, batch_size=32, pos_label=1, seed=42):\n",
    "        assert batch_size >= 2 and batch_size % 2 == 0, \"batch_size must be even\"\n",
    "        self.labels = list(map(int, labels))\n",
    "        self.batch_size = batch_size\n",
    "        self.half = batch_size // 2\n",
    "        self.pos = [i for i, y in enumerate(self.labels) if y == pos_label]\n",
    "        self.neg = [i for i, y in enumerate(self.labels) if y == 0]\n",
    "        if not self.pos or not self.neg:\n",
    "            raise ValueError(\"Need both positive and negative samples.\")\n",
    "\n",
    "        self.steps = math.ceil(len(self.pos) / self.half)  # finite!\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        # shuffle pools each epoch\n",
    "        pos_pool = self.pos[:]\n",
    "        neg_pool = self.neg[:]\n",
    "        self.rng.shuffle(pos_pool)\n",
    "        self.rng.shuffle(neg_pool)\n",
    "\n",
    "        pi = 0\n",
    "        ni = 0\n",
    "        # ensure neg pool long enough\n",
    "        # (repeat if needed so we can draw (steps * half) negatives)\n",
    "        need_neg = self.steps * self.half\n",
    "        if len(neg_pool) < need_neg:\n",
    "            reps = math.ceil(need_neg / len(neg_pool))\n",
    "            neg_pool = (neg_pool * reps)[:need_neg]\n",
    "        # yield exactly `steps` batches\n",
    "        for _ in range(self.steps):\n",
    "            # take half positives\n",
    "            p_end = pi + self.half\n",
    "            if p_end <= len(pos_pool):\n",
    "                p_idx = pos_pool[pi:p_end]\n",
    "                pi = p_end\n",
    "            else:\n",
    "                # wrap and reshuffle remainder to cover all positives once\n",
    "                rem = len(pos_pool) - pi\n",
    "                p_idx = pos_pool[pi:]  # remainder\n",
    "                # reshuffle for the new cycle\n",
    "                self.rng.shuffle(pos_pool)\n",
    "                p_idx += pos_pool[: self.half - rem]\n",
    "                pi = self.half - rem\n",
    "\n",
    "            # take half negatives\n",
    "            n_idx = neg_pool[ni:ni+self.half]\n",
    "            ni += self.half\n",
    "\n",
    "            batch = p_idx + n_idx\n",
    "            self.rng.shuffle(batch)\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce58f08",
   "metadata": {},
   "source": [
    "### 4) Model: ResNet18 with 1-ch init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5128220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class FrameClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        except:\n",
    "            backbone = models.resnet18(pretrained=True)\n",
    "        old = backbone.conv1  # (64,3,7,7)\n",
    "        new = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            new.weight.copy_(old.weight.mean(dim=1, keepdim=True))  # average RGB -> gray\n",
    "        backbone.conv1 = new\n",
    "        backbone.fc = nn.Linear(backbone.fc.in_features, num_classes)\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409646a",
   "metadata": {},
   "source": [
    "### Model: ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbeca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class FrameClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        except:\n",
    "            backbone = models.resnet50(pretrained=True)\n",
    "\n",
    "        # replace first conv (3→1 channels)\n",
    "        old = backbone.conv1  # (64,3,7,7)\n",
    "        new = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            new.weight.copy_(old.weight.mean(dim=1, keepdim=True))  # average RGB to gray\n",
    "        backbone.conv1 = new\n",
    "\n",
    "        # replace classifier head\n",
    "        backbone.fc = nn.Linear(backbone.fc.in_features, num_classes)\n",
    "\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac13a9",
   "metadata": {},
   "source": [
    "### 5) Loss: class-weighted CE (focal optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d303fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weighted_ce(pos_weight=3.0):\n",
    "    # weights for classes [0,1]\n",
    "    w = torch.tensor([1.0, pos_weight], dtype=torch.float32, device=device)\n",
    "    return nn.CrossEntropyLoss(weight=w)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=(1.0, 2.0), gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "        self.gamma = gamma\n",
    "    def forward(self, logits, target):\n",
    "        logp = F.log_softmax(logits, dim=1)\n",
    "        p = torch.exp(logp)\n",
    "        at = self.alpha.to(logits.device)[target]\n",
    "        loss = -at * ((1 - p[range(len(target)), target]) ** self.gamma) * logp[range(len(target)), target]\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793761e6",
   "metadata": {},
   "source": [
    "### 6) Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "810f65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = T.Compose([\n",
    "    T.RandomHorizontalFlip(0.2),\n",
    "    T.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.9, 1.1)),\n",
    "    # T.ColorJitter(0.1, 0.1),\n",
    "    # T.RandomApply([T.GaussianBlur(3)], p=0.2),\n",
    "    T.Normalize(mean=[0.5], std=[0.5])  # to [-1,1]\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b26996",
   "metadata": {},
   "source": [
    "### 7) DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4bbb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TRAIN_DIR = \"D:/dataset/npz_80_tiny\"\n",
    "VAL_DIR   = \"D:/dataset/converted_classifier_npz_compact\"\n",
    "\n",
    "train_files = sorted([f for f in os.listdir(TRAIN_DIR) if f.endswith(\".npz\")])[:210]\n",
    "val_files   = sorted([f for f in os.listdir(VAL_DIR)   if f.endswith(\".npz\")])[210:255]\n",
    "\n",
    "# Preload to RAM (FP16). If you’re tight on RAM, reduce out_size or switch dtype=torch.float32 only for val.\n",
    "train_ds = PreloadedNPZFrameDataset(TRAIN_DIR, train_files, binary=True,\n",
    "                                    out_size=224, resize_mode=\"letterbox\",\n",
    "                                    dtype=torch.float16)\n",
    "val_ds   = PreloadedNPZFrameDataset(VAL_DIR,   val_files,   binary=True,\n",
    "                                    out_size=224, resize_mode=\"letterbox\",\n",
    "                                    dtype=torch.float16)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_sampler=BalancedBatchSampler(train_ds.labels.tolist(), batch_size=16),\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=16,          # val can use plain batching\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7dd840",
   "metadata": {},
   "source": [
    "### 8) Model, Optim, Sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30ecbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import amp\n",
    "\n",
    "model = FrameClassifier(num_classes=2).to(device)\n",
    "\n",
    "# ---- Phase 1: warmup head only ----\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.backbone.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "criterion = make_weighted_ce(pos_weight=3.0)  # try 2–5\n",
    "optimizer = torch.optim.Adam(model.backbone.fc.parameters(), lr=LR_HEAD, weight_decay=WEIGHT_DEC)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "\n",
    "scaler = amp.GradScaler(enabled=(device == \"cuda\"))\n",
    "\n",
    "best_acc = 0.0\n",
    "no_improve = 0\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=\"Train\", total=len(train_loader))\n",
    "    total_loss = 0.0\n",
    "    for imgs, lbls in loop:\n",
    "        # --- move + dtype fix (handles FP16 preloaded tensors) ---\n",
    "        imgs = imgs.to(device, non_blocking=True).float()   # ensure FP32 inputs\n",
    "        lbls = lbls.to(device, non_blocking=True)\n",
    "\n",
    "        # Optional sanity check\n",
    "        assert imgs.ndim == 4 and imgs.shape[1] == 1, f\"Expected [B,1,224,224], got {imgs.shape}\"\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(device == \"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, lbls)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=float(loss.item()))\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_frame_level():\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    loop = tqdm(val_loader, desc=\"Val\", total=len(val_loader))\n",
    "    for imgs, lbls in loop:\n",
    "        imgs = imgs.to(device, non_blocking=True).float()   # ensure FP32 inputs\n",
    "        lbls = lbls.to(device, non_blocking=True)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(device == \"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, lbls)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == lbls).sum().item()\n",
    "        total += lbls.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(lbls.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100.0 * correct / total\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"Background\",\"Positive\"], digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))\n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00759c",
   "metadata": {},
   "source": [
    "### 9) Training: Warmup then unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "430fefd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Phase 1: Warmup head ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:03<00:00, 96.34it/s, loss=0.248] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 66.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.7047 | Val Acc: 65.10%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9981    0.6432    0.7823     36852\n",
      "    Positive     0.0642    0.9515    0.1203       948\n",
      "\n",
      "    accuracy                         0.6510     37800\n",
      "   macro avg     0.5311    0.7973    0.4513     37800\n",
      "weighted avg     0.9746    0.6510    0.7657     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[23704 13148]\n",
      " [   46   902]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:03<00:00, 108.83it/s, loss=0.184]\n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6790 | Val Acc: 68.36%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9974    0.6772    0.8067     36852\n",
      "    Positive     0.0691    0.9314    0.1287       948\n",
      "\n",
      "    accuracy                         0.6836     37800\n",
      "   macro avg     0.5333    0.8043    0.4677     37800\n",
      "weighted avg     0.9741    0.6836    0.7897     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24958 11894]\n",
      " [   65   883]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:03<00:00, 113.97it/s, loss=0.274]\n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6315 | Val Acc: 69.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9976    0.6878    0.8142     36852\n",
      "    Positive     0.0716    0.9357    0.1330       948\n",
      "\n",
      "    accuracy                         0.6940     37800\n",
      "   macro avg     0.5346    0.8117    0.4736     37800\n",
      "weighted avg     0.9744    0.6940    0.7971     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[25345 11507]\n",
      " [   61   887]]\n",
      "== Phase 2: Fine-tune all ==\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:09<00:00, 37.86it/s, loss=0.0902] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1712 | Val Acc: 93.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9975    0.9382    0.9670     36852\n",
      "    Positive     0.2748    0.9103    0.4222       948\n",
      "\n",
      "    accuracy                         0.9375     37800\n",
      "   macro avg     0.6362    0.9243    0.6946     37800\n",
      "weighted avg     0.9794    0.9375    0.9533     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[34575  2277]\n",
      " [   85   863]]\n",
      "✅ Saved best model (val acc = 93.75%)\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 38.98it/s, loss=0.0845] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1141 | Val Acc: 96.37%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9949    0.9677    0.9811     36852\n",
      "    Positive     0.3914    0.8080    0.5274       948\n",
      "\n",
      "    accuracy                         0.9637     37800\n",
      "   macro avg     0.6932    0.8878    0.7542     37800\n",
      "weighted avg     0.9798    0.9637    0.9697     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35661  1191]\n",
      " [  182   766]]\n",
      "✅ Saved best model (val acc = 96.37%)\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:09<00:00, 38.36it/s, loss=0.17]    \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 67.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1993 | Val Acc: 93.86%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9961    0.9407    0.9676     36852\n",
      "    Positive     0.2708    0.8565    0.4116       948\n",
      "\n",
      "    accuracy                         0.9386     37800\n",
      "   macro avg     0.6335    0.8986    0.6896     37800\n",
      "weighted avg     0.9779    0.9386    0.9536     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[34666  2186]\n",
      " [  136   812]]\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 38.87it/s, loss=0.0353]  \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 67.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1699 | Val Acc: 95.42%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9955    0.9574    0.9761     36852\n",
      "    Positive     0.3340    0.8302    0.4764       948\n",
      "\n",
      "    accuracy                         0.9542     37800\n",
      "   macro avg     0.6647    0.8938    0.7262     37800\n",
      "weighted avg     0.9789    0.9542    0.9635     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35283  1569]\n",
      " [  161   787]]\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.03it/s, loss=0.0101]  \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1281 | Val Acc: 96.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9951    0.9723    0.9836     36852\n",
      "    Positive     0.4302    0.8133    0.5628       948\n",
      "\n",
      "    accuracy                         0.9683     37800\n",
      "   macro avg     0.7127    0.8928    0.7732     37800\n",
      "weighted avg     0.9809    0.9683    0.9730     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35831  1021]\n",
      " [  177   771]]\n",
      "✅ Saved best model (val acc = 96.83%)\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.03it/s, loss=0.0104]  \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2576 | Val Acc: 94.76%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9952    0.9508    0.9725     36852\n",
      "    Positive     0.3004    0.8207    0.4398       948\n",
      "\n",
      "    accuracy                         0.9476     37800\n",
      "   macro avg     0.6478    0.8858    0.7061     37800\n",
      "weighted avg     0.9777    0.9476    0.9591     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35040  1812]\n",
      " [  170   778]]\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 38.99it/s, loss=0.0114]  \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1728 | Val Acc: 95.79%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9971    0.9596    0.9780     36852\n",
      "    Positive     0.3623    0.8914    0.5152       948\n",
      "\n",
      "    accuracy                         0.9579     37800\n",
      "   macro avg     0.6797    0.9255    0.7466     37800\n",
      "weighted avg     0.9812    0.9579    0.9664     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35365  1487]\n",
      " [  103   845]]\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.03it/s, loss=0.0316]  \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1777 | Val Acc: 96.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9935    0.9722    0.9827     36852\n",
      "    Positive     0.4108    0.7532    0.5316       948\n",
      "\n",
      "    accuracy                         0.9667     37800\n",
      "   macro avg     0.7022    0.8627    0.7572     37800\n",
      "weighted avg     0.9789    0.9667    0.9714     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35828  1024]\n",
      " [  234   714]]\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 38.93it/s, loss=0.00024] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1451 | Val Acc: 96.96%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9951    0.9737    0.9843     36852\n",
      "    Positive     0.4425    0.8122    0.5729       948\n",
      "\n",
      "    accuracy                         0.9696     37800\n",
      "   macro avg     0.7188    0.8930    0.7786     37800\n",
      "weighted avg     0.9812    0.9696    0.9739     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35882   970]\n",
      " [  178   770]]\n",
      "✅ Saved best model (val acc = 96.96%)\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.03it/s, loss=0.000103]\n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1633 | Val Acc: 97.26%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9943    0.9775    0.9858     36852\n",
      "    Positive     0.4720    0.7838    0.5892       948\n",
      "\n",
      "    accuracy                         0.9726     37800\n",
      "   macro avg     0.7332    0.8806    0.7875     37800\n",
      "weighted avg     0.9812    0.9726    0.9759     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36021   831]\n",
      " [  205   743]]\n",
      "✅ Saved best model (val acc = 97.26%)\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.03it/s, loss=0.000105]\n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1785 | Val Acc: 96.99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9947    0.9744    0.9844     36852\n",
      "    Positive     0.4448    0.7985    0.5713       948\n",
      "\n",
      "    accuracy                         0.9699     37800\n",
      "   macro avg     0.7197    0.8864    0.7779     37800\n",
      "weighted avg     0.9809    0.9699    0.9741     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35907   945]\n",
      " [  191   757]]\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.03it/s, loss=7.47e-5] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1607 | Val Acc: 97.15%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9951    0.9755    0.9852     36852\n",
      "    Positive     0.4608    0.8133    0.5883       948\n",
      "\n",
      "    accuracy                         0.9715     37800\n",
      "   macro avg     0.7280    0.8944    0.7868     37800\n",
      "weighted avg     0.9817    0.9715    0.9753     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35950   902]\n",
      " [  177   771]]\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.06it/s, loss=0.000104]\n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1785 | Val Acc: 97.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9942    0.9782    0.9862     36852\n",
      "    Positive     0.4792    0.7795    0.5936       948\n",
      "\n",
      "    accuracy                         0.9732     37800\n",
      "   macro avg     0.7367    0.8789    0.7899     37800\n",
      "weighted avg     0.9813    0.9732    0.9763     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36049   803]\n",
      " [  209   739]]\n",
      "✅ Saved best model (val acc = 97.32%)\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.04it/s, loss=5.97e-5] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1858 | Val Acc: 97.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9946    0.9774    0.9859     36852\n",
      "    Positive     0.4741    0.7922    0.5932       948\n",
      "\n",
      "    accuracy                         0.9728     37800\n",
      "   macro avg     0.7343    0.8848    0.7896     37800\n",
      "weighted avg     0.9815    0.9728    0.9761     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36019   833]\n",
      " [  197   751]]\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.05it/s, loss=3.1e-6]  \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1850 | Val Acc: 97.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9938    0.9806    0.9872     36852\n",
      "    Positive     0.5028    0.7627    0.6060       948\n",
      "\n",
      "    accuracy                         0.9751     37800\n",
      "   macro avg     0.7483    0.8716    0.7966     37800\n",
      "weighted avg     0.9815    0.9751    0.9776     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36137   715]\n",
      " [  225   723]]\n",
      "✅ Saved best model (val acc = 97.51%)\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 38.78it/s, loss=1.07e-5] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1906 | Val Acc: 97.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9938    0.9804    0.9871     36852\n",
      "    Positive     0.5000    0.7627    0.6040       948\n",
      "\n",
      "    accuracy                         0.9749     37800\n",
      "   macro avg     0.7469    0.8715    0.7955     37800\n",
      "weighted avg     0.9814    0.9749    0.9774     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36129   723]\n",
      " [  225   723]]\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.04it/s, loss=7.55e-6] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1939 | Val Acc: 97.44%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9942    0.9794    0.9868     36852\n",
      "    Positive     0.4933    0.7795    0.6043       948\n",
      "\n",
      "    accuracy                         0.9744     37800\n",
      "   macro avg     0.7438    0.8795    0.7955     37800\n",
      "weighted avg     0.9817    0.9744    0.9772     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36093   759]\n",
      " [  209   739]]\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.01it/s, loss=7.11e-6] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2002 | Val Acc: 97.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9941    0.9798    0.9869     36852\n",
      "    Positive     0.4953    0.7722    0.6035       948\n",
      "\n",
      "    accuracy                         0.9746     37800\n",
      "   macro avg     0.7447    0.8760    0.7952     37800\n",
      "weighted avg     0.9815    0.9746    0.9772     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36106   746]\n",
      " [  216   732]]\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.07it/s, loss=1.42e-5] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2027 | Val Acc: 97.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9945    0.9788    0.9866     36852\n",
      "    Positive     0.4892    0.7911    0.6046       948\n",
      "\n",
      "    accuracy                         0.9740     37800\n",
      "   macro avg     0.7419    0.8849    0.7956     37800\n",
      "weighted avg     0.9819    0.9740    0.9770     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36069   783]\n",
      " [  198   750]]\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 346/346 [00:08<00:00, 39.03it/s, loss=4.99e-5] \n",
      "Val: 100%|██████████| 591/591 [00:08<00:00, 68.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1955 | Val Acc: 96.99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9951    0.9739    0.9844     36852\n",
      "    Positive     0.4448    0.8122    0.5748       948\n",
      "\n",
      "    accuracy                         0.9699     37800\n",
      "   macro avg     0.7199    0.8931    0.7796     37800\n",
      "weighted avg     0.9813    0.9699    0.9741     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35891   961]\n",
      " [  178   770]]\n",
      "⏹️ Early stopping.\n",
      "Training finished. Best validation accuracy = 97.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"== Phase 1: Warmup head ==\")\n",
    "for epoch in range(3):  # 3–5 warmup epochs\n",
    "    tl = train_one_epoch()\n",
    "    val_acc, val_loss = validate_frame_level()\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "# ---- Phase 2: unfreeze all + fine-tune ----\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_ALL, weight_decay=WEIGHT_DEC)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "\n",
    "print(\"== Phase 2: Fine-tune all ==\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    tl = train_one_epoch()\n",
    "    val_acc, val_loss = validate_frame_level()\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    # early stopping + checkpoint\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"best_acc\": best_acc\n",
    "        }, SAVE_PATH)\n",
    "        print(f\"✅ Saved best model (val acc = {best_acc:.2f}%)\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(\"⏹️ Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(f\"Training finished. Best validation accuracy = {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716d47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import amp\n",
    "\n",
    "model = FrameClassifier(num_classes=2).to(device)\n",
    "\n",
    "# ---- Phase 1: warmup head only ----\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.backbone.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "criterion = make_weighted_ce(pos_weight=3.0)  # try 2–5\n",
    "optimizer = torch.optim.Adam(model.backbone.fc.parameters(), lr=LR_HEAD, weight_decay=WEIGHT_DEC)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "\n",
    "scaler = amp.GradScaler(enabled=(device == \"cuda\"))\n",
    "\n",
    "best_acc = 0.0\n",
    "no_improve = 0\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=\"Train\", total=len(train_loader))\n",
    "    total_loss = 0.0\n",
    "    for imgs, lbls in loop:\n",
    "        # --- move + dtype fix (handles FP16 preloaded tensors) ---\n",
    "        imgs = imgs.to(device, non_blocking=True).float()   # ensure FP32 inputs\n",
    "        lbls = lbls.to(device, non_blocking=True)\n",
    "\n",
    "        # Optional sanity check\n",
    "        assert imgs.ndim == 4 and imgs.shape[1] == 1, f\"Expected [B,1,224,224], got {imgs.shape}\"\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(device == \"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, lbls)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=float(loss.item()))\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_frame_level():\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    loop = tqdm(val_loader, desc=\"Val\", total=len(val_loader))\n",
    "    for imgs, lbls in loop:\n",
    "        imgs = imgs.to(device, non_blocking=True).float()   # ensure FP32 inputs\n",
    "        lbls = lbls.to(device, non_blocking=True)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(device == \"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, lbls)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == lbls).sum().item()\n",
    "        total += lbls.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(lbls.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100.0 * correct / total\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"Background\",\"Positive\"], digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))\n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eff289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Phase 1: Warmup head ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:09<00:00, 72.48it/s, loss=0.215] \n",
      "Val: 100%|██████████| 2363/2363 [00:24<00:00, 96.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6434 | Val Acc: 69.79%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9982    0.6914    0.8169     36852\n",
      "    Positive     0.0734    0.9504    0.1363       948\n",
      "\n",
      "    accuracy                         0.6979     37800\n",
      "   macro avg     0.5358    0.8209    0.4766     37800\n",
      "weighted avg     0.9750    0.6979    0.7999     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[25480 11372]\n",
      " [   47   901]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:08<00:00, 84.31it/s, loss=0.311] \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 103.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.8229 | Val Acc: 65.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9983    0.6454    0.7839     36852\n",
      "    Positive     0.0650    0.9578    0.1217       948\n",
      "\n",
      "    accuracy                         0.6532     37800\n",
      "   macro avg     0.5316    0.8016    0.4528     37800\n",
      "weighted avg     0.9749    0.6532    0.7673     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[23783 13069]\n",
      " [   40   908]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:08<00:00, 84.77it/s, loss=0.281] \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 102.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5710 | Val Acc: 73.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9977    0.7334    0.8454     36852\n",
      "    Positive     0.0826    0.9335    0.1518       948\n",
      "\n",
      "    accuracy                         0.7384     37800\n",
      "   macro avg     0.5402    0.8335    0.4986     37800\n",
      "weighted avg     0.9747    0.7384    0.8280     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27028  9824]\n",
      " [   63   885]]\n",
      "== Phase 2: Fine-tune all ==\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 26.71it/s, loss=0.012]  \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 102.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3939 | Val Acc: 89.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9987    0.8897    0.9410     36852\n",
      "    Positive     0.1820    0.9536    0.3056       948\n",
      "\n",
      "    accuracy                         0.8913     37800\n",
      "   macro avg     0.5903    0.9217    0.6233     37800\n",
      "weighted avg     0.9782    0.8913    0.9251     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[32788  4064]\n",
      " [   44   904]]\n",
      "✅ Saved best model (val acc = 89.13%)\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 26.63it/s, loss=0.0103]  \n",
      "Val: 100%|██████████| 2363/2363 [00:23<00:00, 101.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1072 | Val Acc: 95.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9955    0.9628    0.9789     36852\n",
      "    Positive     0.3648    0.8312    0.5071       948\n",
      "\n",
      "    accuracy                         0.9595     37800\n",
      "   macro avg     0.6802    0.8970    0.7430     37800\n",
      "weighted avg     0.9797    0.9595    0.9670     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35480  1372]\n",
      " [  160   788]]\n",
      "✅ Saved best model (val acc = 95.95%)\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 26.71it/s, loss=0.104]   \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 103.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3055 | Val Acc: 89.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9987    0.8912    0.9419     36852\n",
      "    Positive     0.1841    0.9546    0.3087       948\n",
      "\n",
      "    accuracy                         0.8928     37800\n",
      "   macro avg     0.5914    0.9229    0.6253     37800\n",
      "weighted avg     0.9783    0.8928    0.9260     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[32842  4010]\n",
      " [   43   905]]\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 27.10it/s, loss=0.595]   \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 103.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1334 | Val Acc: 95.37%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9964    0.9560    0.9758     36852\n",
      "    Positive     0.3362    0.8671    0.4845       948\n",
      "\n",
      "    accuracy                         0.9537     37800\n",
      "   macro avg     0.6663    0.9115    0.7302     37800\n",
      "weighted avg     0.9799    0.9537    0.9635     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35229  1623]\n",
      " [  126   822]]\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 27.19it/s, loss=0.0234]  \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 102.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0878 | Val Acc: 97.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9937    0.9772    0.9854     36852\n",
      "    Positive     0.4608    0.7574    0.5730       948\n",
      "\n",
      "    accuracy                         0.9717     37800\n",
      "   macro avg     0.7273    0.8673    0.7792     37800\n",
      "weighted avg     0.9803    0.9717    0.9750     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36012   840]\n",
      " [  230   718]]\n",
      "✅ Saved best model (val acc = 97.17%)\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 27.10it/s, loss=0.0491]  \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 102.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2308 | Val Acc: 93.39%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9979    0.9341    0.9650     36852\n",
      "    Positive     0.2650    0.9230    0.4118       948\n",
      "\n",
      "    accuracy                         0.9339     37800\n",
      "   macro avg     0.6314    0.9286    0.6884     37800\n",
      "weighted avg     0.9795    0.9339    0.9511     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[34425  2427]\n",
      " [   73   875]]\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 26.73it/s, loss=0.0013]  \n",
      "Val: 100%|██████████| 2363/2363 [00:23<00:00, 101.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1492 | Val Acc: 95.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9974    0.9538    0.9751     36852\n",
      "    Positive     0.3342    0.9019    0.4877       948\n",
      "\n",
      "    accuracy                         0.9525     37800\n",
      "   macro avg     0.6658    0.9278    0.7314     37800\n",
      "weighted avg     0.9807    0.9525    0.9629     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35149  1703]\n",
      " [   93   855]]\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 26.58it/s, loss=0.0112]  \n",
      "Val: 100%|██████████| 2363/2363 [00:23<00:00, 101.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1179 | Val Acc: 96.82%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9942    0.9730    0.9835     36852\n",
      "    Positive     0.4265    0.7806    0.5516       948\n",
      "\n",
      "    accuracy                         0.9682     37800\n",
      "   macro avg     0.7104    0.8768    0.7676     37800\n",
      "weighted avg     0.9800    0.9682    0.9727     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35857   995]\n",
      " [  208   740]]\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 27.00it/s, loss=0.00418] \n",
      "Val: 100%|██████████| 2363/2363 [00:22<00:00, 102.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1232 | Val Acc: 96.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9939    0.9740    0.9839     36852\n",
      "    Positive     0.4317    0.7669    0.5524       948\n",
      "\n",
      "    accuracy                         0.9688     37800\n",
      "   macro avg     0.7128    0.8705    0.7681     37800\n",
      "weighted avg     0.9798    0.9688    0.9730     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35895   957]\n",
      " [  221   727]]\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 691/691 [00:25<00:00, 26.92it/s, loss=0.00027] \n",
      "Val: 100%|██████████| 2363/2363 [00:23<00:00, 102.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1255 | Val Acc: 97.12%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background     0.9943    0.9760    0.9851     36852\n",
      "    Positive     0.4569    0.7838    0.5773       948\n",
      "\n",
      "    accuracy                         0.9712     37800\n",
      "   macro avg     0.7256    0.8799    0.7812     37800\n",
      "weighted avg     0.9809    0.9712    0.9749     37800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35969   883]\n",
      " [  205   743]]\n",
      "⏹️ Early stopping.\n",
      "Training finished. Best validation accuracy = 97.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"== Phase 1: Warmup head ==\")\n",
    "for epoch in range(3):  # 3–5 warmup epochs\n",
    "    tl = train_one_epoch()\n",
    "    val_acc, val_loss = validate_frame_level()\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "# ---- Phase 2: unfreeze all + fine-tune ----\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_ALL, weight_decay=WEIGHT_DEC)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "\n",
    "print(\"== Phase 2: Fine-tune all ==\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    tl = train_one_epoch()\n",
    "    val_acc, val_loss = validate_frame_level()\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    # early stopping + checkpoint\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"best_acc\": best_acc\n",
    "        }, SAVE_PATH)\n",
    "        print(f\"✅ Saved best model (val acc = {best_acc:.2f}%)\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(\"⏹️ Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(f\"Training finished. Best validation accuracy = {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad6cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 45 cases (tolerance=±0)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:42<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Summary ======\n",
      "Correct best-frame picks: 38/45 (84.4%)\n",
      "(tolerance = ±0, MA=7, topk=1, thresh=None)\n",
      "d42fb920-5df1-4341-93df-480c17355e44.npz: best= 804  prob=0.986  dist_to_pos=  0  HIT\n",
      "d5471cfd-6090-4d42-9a95-67ccbfbf612e.npz: best=  48  prob=0.922  dist_to_pos=  0  HIT\n",
      "d571d4e1-ff80-44b9-a481-07961c6a1208.npz: best=  52  prob=0.987  dist_to_pos=  0  HIT\n",
      "d5c3cfee-53ac-4021-8c1b-098c189f630e.npz: best= 623  prob=0.997  dist_to_pos=  0  HIT\n",
      "d5f8c859-de93-4a50-b324-1ae4ad0267d4.npz: best= 208  prob=0.928  dist_to_pos=  0  HIT\n",
      "d624338f-d09b-4bda-bbc3-3fa417015d6b.npz: best=  78  prob=0.999  dist_to_pos=  0  HIT\n",
      "d77b6ece-da17-4f88-818c-0c7340b3e54f.npz: best=  58  prob=0.999  dist_to_pos=  0  HIT\n",
      "d812091a-3635-4d51-9290-6adb3aa8681e.npz: best=  37  prob=0.979  dist_to_pos=  0  HIT\n",
      "d8c3665a-4dc3-40ce-b716-f30aab365332.npz: best= 181  prob=0.578  dist_to_pos=410  MISS\n",
      "db9d468d-cb20-4d5e-b059-31728f5950e6.npz: best=  50  prob=0.973  dist_to_pos=  0  HIT\n",
      "dc0cbbdf-e4bb-4de5-958a-10576129e440.npz: best=  50  prob=1.000  dist_to_pos=  0  HIT\n",
      "dc381d50-124d-4bc8-b504-9c9c3a3ae697.npz: best= 182  prob=0.995  dist_to_pos=  0  HIT\n",
      "dcdcb9a4-fec7-45a2-b2b7-a282f963c551.npz: best=  60  prob=0.953  dist_to_pos=  0  HIT\n",
      "de35b365-6308-4974-b2fc-976e26584810.npz: best= 650  prob=0.822  dist_to_pos=  0  HIT\n",
      "de45de1a-2482-4024-ac8b-c18c4834b379.npz: best=  51  prob=0.981  dist_to_pos=  0  HIT\n",
      "de93dac8-41e0-4b03-946e-0accda6010af.npz: best= 199  prob=0.682  dist_to_pos=  0  HIT\n",
      "de964751-ec9d-4c53-9da3-9d7f200987b1.npz: best=  37  prob=1.000  dist_to_pos=  0  HIT\n",
      "decd2d84-79a2-4239-b802-5afdf318e7e6.npz: best=  43  prob=0.999  dist_to_pos=  0  HIT\n",
      "e3670fa9-574c-4fbc-89af-f69aad63696d.npz: best= 317  prob=0.998  dist_to_pos=  0  HIT\n",
      "e5053a72-46f6-496d-8252-c8b531b5039b.npz: best= 604  prob=0.736  dist_to_pos=  0  HIT\n",
      "e5a2d914-a35c-4207-9bc8-5e5cee7dbfba.npz: best= 467  prob=0.905  dist_to_pos=  3  MISS\n",
      "e608e364-6898-442c-be0f-aea8d7735c15.npz: best=  53  prob=0.974  dist_to_pos=  0  HIT\n",
      "e9025780-a9bb-4300-be4e-fb220e824646.npz: best= 207  prob=1.000  dist_to_pos=  0  HIT\n",
      "e9043ff5-f8a4-4095-bc44-26232e1be011.npz: best=  16  prob=0.978  dist_to_pos=  0  HIT\n",
      "ea2a8fbf-f7fe-43f4-9e0d-1da0ae9b1a0c.npz: best=  32  prob=0.977  dist_to_pos=  0  HIT\n",
      "ea724ff0-9990-4557-ab53-16f2fe1f1c8f.npz: best= 185  prob=0.980  dist_to_pos=  0  HIT\n",
      "ea86047a-bae4-464b-a2ed-015935bebb2a.npz: best=  63  prob=1.000  dist_to_pos=  0  HIT\n",
      "ebadcfcb-a682-4493-8502-2adc194bba8c.npz: best= 469  prob=1.000  dist_to_pos=  0  HIT\n",
      "ec65aa35-d54c-44da-80a4-883f631c345e.npz: best= 175  prob=0.972  dist_to_pos=142  MISS\n",
      "ee2e6220-b2f3-4c8e-9c85-f04ed0a6b6f7.npz: best= 492  prob=0.999  dist_to_pos=  0  HIT\n",
      "eee8da44-8db7-4c9e-b52d-b6d461158a4e.npz: best= 629  prob=0.989  dist_to_pos=  0  HIT\n",
      "f1fcabfc-f998-44c7-8420-c7a5ae5aaab7.npz: best=  54  prob=0.376  dist_to_pos=  1  MISS\n",
      "f256d725-9b06-4a88-a6b5-f9eee0f050f4.npz: best= 190  prob=0.992  dist_to_pos=  0  HIT\n",
      "f4488c3c-556e-43bd-95f9-ae4cbb7c7093.npz: best= 636  prob=0.990  dist_to_pos=122  MISS\n",
      "f4bebd1e-d3ca-4186-902a-2b6ef9391060.npz: best= 293  prob=0.986  dist_to_pos=  0  HIT\n",
      "f5611c30-d04b-4691-9bd6-1e6de392a63c.npz: best= 603  prob=0.758  dist_to_pos=382  MISS\n",
      "f5a702f0-d759-4b53-8215-462e8145e638.npz: best= 168  prob=0.981  dist_to_pos=  0  HIT\n",
      "f5e853b1-9465-40b0-a246-7d3f6cb94de7.npz: best= 477  prob=1.000  dist_to_pos=  0  HIT\n",
      "f5e97e20-ad47-46e4-bf35-3f0c01ff51d0.npz: best=  84  prob=0.969  dist_to_pos=  0  HIT\n",
      "f8039e25-4652-440c-9476-b425f3fccb22.npz: best=  54  prob=0.984  dist_to_pos=  0  HIT\n",
      "f9ba7ffd-bc66-4da6-b97d-1286d760a184.npz: best=  52  prob=0.999  dist_to_pos=  3  MISS\n",
      "fc167d1b-045a-4057-936d-4862644af1f3.npz: best=  88  prob=1.000  dist_to_pos=  0  HIT\n",
      "fc63df40-f6ca-4917-99ba-dbe4310a6d04.npz: best= 617  prob=0.984  dist_to_pos=  0  HIT\n",
      "fdfd752d-2d83-4452-a3ba-97a626676334.npz: best= 227  prob=0.966  dist_to_pos=  0  HIT\n",
      "fe236600-a41c-4d26-b4ea-6d3ff109cf41.npz: best= 285  prob=0.693  dist_to_pos=  0  HIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, torch\n",
    "import torch.nn.functional as F\n",
    "from torch import amp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Config (edit these)\n",
    "# -----------------------------\n",
    "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_PATH  = \"D:/acouslic-ai-cse4622/saved_weights/best_frame_classifier_allinone.pth\"\n",
    "TEST_DIR    = \"D:/dataset/converted_classifier_npz_compact\"   # full 840-frame npz files\n",
    "START_IDX   = 255   # where your test split starts\n",
    "NUM_CASES   = 45\n",
    "IMAGE_SIZE  = 224\n",
    "MA_WINDOW   = 7     # temporal smoothing (moving average)\n",
    "TOPK        = 1     # use top-1 for \"best frame\"\n",
    "THRESH      = None  # or e.g. 0.6 to require minimum smoothed prob\n",
    "TOLERANCE   = 0     # 0 = exact frame; try 3 for ±3 frames\n",
    "\n",
    "# -----------------------------\n",
    "# Utils (match your training preprocessing)\n",
    "# -----------------------------\n",
    "def letterbox_to_square_tensor(x: torch.Tensor, size=IMAGE_SIZE) -> torch.Tensor:\n",
    "    \"\"\"x: (B,1,H,W) or (1,H,W) in [0,1] -> square pad -> resize to (..,1,size,size)\"\"\"\n",
    "    is_batched = (x.dim() == 4)\n",
    "    if not is_batched: x = x.unsqueeze(0)\n",
    "    _, _, H, W = x.shape\n",
    "    s = max(H, W)\n",
    "    pad_h = (s - H) // 2\n",
    "    pad_w = (s - W) // 2\n",
    "    x = F.pad(x, (pad_w, s-W-pad_w, pad_h, s-H-pad_h))\n",
    "    x = F.interpolate(x, size=(size, size), mode=\"bilinear\", align_corners=False)\n",
    "    return x if is_batched else x.squeeze(0)\n",
    "\n",
    "def moving_average(a: np.ndarray, w: int = 7):\n",
    "    if w <= 1: return a\n",
    "    k = np.ones(w, dtype=np.float32) / w\n",
    "    return np.convolve(a, k, mode=\"same\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_over_frames(npz_path, model, batch_size=128):\n",
    "    d = np.load(npz_path, mmap_mode=\"r\")\n",
    "    frames = d[\"image\"]  # (T,H,W) uint8\n",
    "    Tn = len(frames)\n",
    "    probs = np.zeros(Tn, dtype=np.float32)\n",
    "    off = 0\n",
    "    while off < Tn:\n",
    "        chunk = frames[off:off+batch_size]\n",
    "        x = torch.from_numpy(chunk).unsqueeze(1).float() / 255.0      # (B,1,H,W) [0,1]\n",
    "        x = letterbox_to_square_tensor(x, size=IMAGE_SIZE)            # (B,1,S,S)\n",
    "        x = (x - 0.5) / 0.5                                           # [-1,1]\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(x)\n",
    "            p = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        probs[off:off+len(p)] = p\n",
    "        off += len(p)\n",
    "    return probs\n",
    "\n",
    "@torch.no_grad()\n",
    "def pick_best_frame(npz_path, model, ma_window=7, topk=1, thresh=None):\n",
    "    \"\"\"Returns best_idx (int), best_score (float), idx_topk (np.ndarray), raw_probs, smoothed_probs.\"\"\"\n",
    "    probs = predict_probs_over_frames(npz_path, model)\n",
    "    sm = moving_average(probs, w=ma_window)\n",
    "    idx_sorted = np.argsort(-sm)\n",
    "    idx_topk = idx_sorted[:topk]\n",
    "    if thresh is not None:\n",
    "        idx_topk = np.array([i for i in idx_topk if sm[i] >= thresh], dtype=int)\n",
    "        if len(idx_topk) == 0:\n",
    "            idx_topk = np.array([int(np.argmax(sm))], dtype=int)\n",
    "    best_idx = int(idx_topk[0])\n",
    "    best_score = float(sm[best_idx])\n",
    "    return best_idx, best_score, idx_topk, probs, sm\n",
    "\n",
    "def load_binary_labels(npz_path):\n",
    "    y = np.load(npz_path, mmap_mode=\"r\")[\"label\"].astype(np.int64)\n",
    "    y[y == 2] = 1\n",
    "    return y\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "model = FrameClassifier(num_classes=2).to(DEVICE)\n",
    "ckpt = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "state = ckpt.get(\"model_state\", ckpt)  # support plain state_dict too\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# Pick 45 test files and evaluate\n",
    "# -----------------------------\n",
    "files = sorted([f for f in os.listdir(TEST_DIR) if f.endswith(\".npz\")])\n",
    "test_files = files[START_IDX:START_IDX+NUM_CASES]\n",
    "assert len(test_files) > 0, \"No test files selected.\"\n",
    "\n",
    "correct = 0\n",
    "details = []\n",
    "\n",
    "print(f\"Evaluating {len(test_files)} cases (tolerance=±{TOLERANCE})...\\n\")\n",
    "for f in tqdm(test_files):\n",
    "    path = os.path.join(TEST_DIR, f)\n",
    "    y = load_binary_labels(path)\n",
    "    pos_idx = np.where(y == 1)[0]  # ground truth positive frames\n",
    "\n",
    "    best_idx, best_score, idx_topk, probs, sm = pick_best_frame(\n",
    "        path, model, ma_window=MA_WINDOW, topk=TOPK, thresh=THRESH\n",
    "    )\n",
    "\n",
    "    if len(pos_idx) == 0:\n",
    "        hit = (y[best_idx] == 0)  # no positives: \"correct\" if best is background\n",
    "        dist = 0\n",
    "    else:\n",
    "        # exact or ±tolerance match\n",
    "        dist = int(np.min(np.abs(pos_idx - best_idx)))\n",
    "        hit = (dist <= TOLERANCE)\n",
    "\n",
    "    correct += int(hit)\n",
    "    details.append((f, best_idx, best_score, dist, hit))\n",
    "\n",
    "# -----------------------------\n",
    "# Summary\n",
    "# -----------------------------\n",
    "print(\"\\n====== Summary ======\")\n",
    "print(f\"Correct best-frame picks: {correct}/{len(test_files)} ({100.0*correct/len(test_files):.1f}%)\")\n",
    "print(f\"(tolerance = ±{TOLERANCE}, MA={MA_WINDOW}, topk={TOPK}, thresh={THRESH})\")\n",
    "\n",
    "# Optional: show a few per-case lines\n",
    "for f, bi, bs, d, h in details[:45]:\n",
    "    print(f\"{f}: best={bi:4d}  prob={bs:.3f}  dist_to_pos={d:3d}  {'HIT' if h else 'MISS'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755211fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
